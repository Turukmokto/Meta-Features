{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d718a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/2113948404.py:8: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr, spearmanr\n",
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/2113948404.py:8: DeprecationWarning: Please use `spearmanr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr, spearmanr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.arff import loadarff\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.stats import pearsonr, spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def unify_item(item):\n",
    "    if isinstance(item, bytes):\n",
    "        return item.decode()\n",
    "    return item\n",
    "\n",
    "\n",
    "def chi_square(x, y):\n",
    "    df = pd.DataFrame({'X': x, 'Y': y})\n",
    "    crosstab = pd.crosstab(index=df['X'], columns=df['Y'])\n",
    "    res = chi2_contingency(crosstab.values)\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "def mean_corr(x, y):\n",
    "    return corr_with(x, y).values.mean()\n",
    "\n",
    "\n",
    "def min_corr(x, y):\n",
    "    return corr_with(x, y).values.min()\n",
    "\n",
    "\n",
    "def max_corr(x, y):\n",
    "    return corr_with(x, y).values.max()\n",
    "\n",
    "\n",
    "def corr_with(x, y):\n",
    "    y_str = list(map(unify_item, y))\n",
    "    dummies = pd.Series(y_str).str.get_dummies()\n",
    "    corrwith = dummies.corrwith(pd.Series(x))\n",
    "    return corrwith\n",
    "\n",
    "\n",
    "def entropy(Y):\n",
    "    unique, count = np.unique(Y, return_counts=True)\n",
    "    prob = count / len(Y)\n",
    "    en = np.sum((-1) * prob * np.log(prob))\n",
    "    return en\n",
    "\n",
    "\n",
    "def cond_entropy(X, Y):\n",
    "    return entropy(np.c_[Y, X]) - entropy(X)\n",
    "\n",
    "\n",
    "def merge_dicts(from_dict, to_dict, key_transform=None, value_as_list=True):\n",
    "    for func in from_dict:\n",
    "        res_key_name = func if key_transform is None else key_transform(func)\n",
    "        if value_as_list:\n",
    "            if res_key_name not in to_dict:\n",
    "                to_dict[res_key_name] = []\n",
    "            to_dict[res_key_name].append(from_dict[func])\n",
    "        else:\n",
    "            to_dict[res_key_name] = from_dict[func]\n",
    "\n",
    "\n",
    "def vectorize_xs(xs):\n",
    "    dv = DictVectorizer()\n",
    "    xs_ = list(map(lambda x: dict(map(lambda t: (str(t[0]), t[1]), list(enumerate(x)))), xs.values))\n",
    "    vectorized_xs = dv.fit_transform(xs_).toarray()\n",
    "    return vectorized_xs\n",
    "\n",
    "\n",
    "def norm_min_max(xs_):\n",
    "    xs = xs_.copy()\n",
    "    for col in range(xs.shape[1]):\n",
    "        delta = (xs[:, col].max() - xs[:, col].min())\n",
    "        if 0.0 == delta:\n",
    "            xs[:, col] = xs[:, col] * 0\n",
    "        else:\n",
    "            xs[:, col] = (xs[:, col] - xs[:, col].min()) / delta\n",
    "    return xs\n",
    "\n",
    "\n",
    "def process_one_column(*args, feature_type):\n",
    "    arr = np.nan_to_num(*args, nan=0)\n",
    "    used_functions = extraction_functions[feature_type]\n",
    "    cur_results = {}\n",
    "    for func in used_functions:\n",
    "        cur_results[func] = used_functions[func](arr)\n",
    "    return cur_results\n",
    "\n",
    "\n",
    "def get_statistic_features(xs, f_type='numeric'):\n",
    "    first_stat_features = {}\n",
    "    for feature_num in range(xs.shape[1]):\n",
    "        res_dict = process_one_column(xs[:, feature_num], feature_type=f_type)\n",
    "        merge_dicts(res_dict, first_stat_features)\n",
    "    result_stat_features = {}\n",
    "    for stat_name in first_stat_features:\n",
    "        stats = first_stat_features[stat_name]\n",
    "        if len(stats) == 1:\n",
    "            result_stat_features[stat_name] = stats[0]\n",
    "        else:\n",
    "            res_dict = process_one_column(stats, feature_type='numeric')\n",
    "            merge_dicts(res_dict, result_stat_features,\n",
    "                        key_transform=lambda s: f\"{stat_name}/{s}\",\n",
    "                        value_as_list=False)\n",
    "    return result_stat_features\n",
    "\n",
    "\n",
    "def get_all_features(df):\n",
    "    basic_features = {\n",
    "        \"objects_count\": df_data.shape[0],\n",
    "        \"features_count\": df_data.shape[1] - 1,\n",
    "        \"numeric_count\": len(df.select_dtypes(include=[np.number]).axes[1]),\n",
    "        \"nominal_count\": len(df.select_dtypes(include=[object]).axes[1]) - 1,\n",
    "    }\n",
    "    df_copy = df.copy()\n",
    "    name_pred = df_copy.columns[-1]\n",
    "    x = df_copy.drop(name_pred, axis=1)\n",
    "    y = df_copy[name_pred]\n",
    "    xs = vectorize_xs(x)\n",
    "    xs = norm_min_max(xs)\n",
    "    ys = y.values\n",
    "    xstat_features = get_statistic_features(xs, 'numeric')\n",
    "    ystat_features = get_statistic_features(ys[:, None], 'nominal')\n",
    "    dt = DecisionTreeClassifier(random_state=0)\n",
    "    dt.fit(xs, ys)\n",
    "    struct_features = {\n",
    "        \"tree_n_leaves\": dt.get_n_leaves(),\n",
    "        \"tree_max_depth\": dt.get_depth(),\n",
    "    }\n",
    "    class_features = {}\n",
    "    all_scores = dict()\n",
    "    for classifier_name in available_classifiers:\n",
    "        cls = available_classifiers[classifier_name]()\n",
    "        cls.fit(xs, ys)\n",
    "        pred = cls.predict(xs)\n",
    "        score = f1_score(ys, pred, average='micro')\n",
    "        all_scores[classifier_name] = score\n",
    "    best = [k for k, v in all_scores.items() if v == max(all_scores.values())][0]\n",
    "    best_algo = [best]\n",
    "    return {'best_algo': best_algo, **basic_features,\n",
    "            **xstat_features, **ystat_features, **struct_features,\n",
    "            **class_features, **all_scores}\n",
    "\n",
    "\n",
    "decision_tree = lambda: DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "naive_bayes = lambda: GaussianNB()\n",
    "SVM_poly = lambda: SVC(kernel='poly', random_state=0)\n",
    "\n",
    "available_classifiers = {\n",
    "    'decision_tree': decision_tree,\n",
    "    'naive_bayes': naive_bayes,\n",
    "    'SVM_poly': SVM_poly,\n",
    "}\n",
    "\n",
    "extraction_functions = {\n",
    "    \"numeric\": {\n",
    "        \"min\": min,\n",
    "        \"max\": max,\n",
    "        \"mean\": lambda x: sum(x) / len(x),\n",
    "    },\n",
    "    \"nominal\": {\n",
    "        \"uniques_count\": lambda x: len(set(x)),\n",
    "        \"entropy\": entropy,\n",
    "    },\n",
    "    \"nominal/nominal\": {\n",
    "        \"cond_entropy\": cond_entropy,\n",
    "        \"chi_square\": chi_square,\n",
    "    },\n",
    "    \"numeric/nominal\": {\n",
    "        \"mean_corr\": mean_corr,\n",
    "        \"max_corr\": max_corr,\n",
    "        \"min_corr\": min_corr,\n",
    "    },\n",
    "    \"numeric/numeric\": {\n",
    "        \"pearsonr\": pearsonr,\n",
    "        \"spearmanr\": spearmanr,\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b10cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([['SVM_poly'], 625, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 2, 0.6900707444437642, 120, 11, 0.88, 0.9552, 0.9792])\n",
      "dict_values([['SVM_poly'], 625, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 2, 0.6900707444437642, 120, 11, 0.88, 0.9552, 0.9792])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/827772248.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['binaryClass'][new_data['binaryClass'] == 'N'] = 2\n",
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/827772248.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['binaryClass'][new_data['binaryClass'] == 'P'] = 'N'\n",
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/827772248.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['binaryClass'][new_data['binaryClass'] == 2] = 'P'\n"
     ]
    }
   ],
   "source": [
    "name = '/Users/esbessonngmail.com/Downloads/OpenML/data/997.arff'\n",
    "raw_data = loadarff(name)\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "str_df = df_data.select_dtypes([object])\n",
    "str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "for col in str_df:\n",
    "    df_data[col] = str_df[col]\n",
    "\n",
    "features = get_all_features(df_data)\n",
    "print(features.values())\n",
    "\n",
    "\n",
    "new_data = df_data.copy().sample(frac=1)\n",
    "new_data['binaryClass'][new_data['binaryClass'] == 'N'] = 2\n",
    "new_data['binaryClass'][new_data['binaryClass'] == 'P'] = 'N'\n",
    "new_data['binaryClass'][new_data['binaryClass'] == 2] = 'P'\n",
    "\n",
    "features = get_all_features(new_data)\n",
    "print(features.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal file 864.arff\n",
      "dict_values([['decision_tree'], 60, 7, 6, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6552941176470591, 0.5920631921612787, 2, 0.6881388137135884, 16, 10, 0.85, 0.7333333333333333, 0.8000000000000002])\n",
      "Nominal file 921.arff\n",
      "dict_values([['decision_tree'], 132, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22386814574314567, 0.5, 0.3447736291486291, 2, 0.6465036520083403, 11, 6, 0.9848484848484849, 0.9166666666666666, 0.9772727272727273])\n",
      "Numeric file 188.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1447.arff\n",
      "dict_values([['decision_tree'], 327, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02326757702858407, 0.6889283482950253, 0.13183274313567822, 2, 0.3834111178560703, 41, 10, 0.9143730886850153, 0.8226299694189603, 0.8868501529051988])\n",
      "Numeric file 472.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 999.arff\n",
      "dict_values([['decision_tree'], 226, 69, 0, 69, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.004424778761061947, 0.995575221238938, 0.4285714285714282, 2, 0.5647526758715391, 11, 7, 0.9867256637168141, 0.9601769911504425, 0.9867256637168141])\n",
      "Numeric file 560.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 425.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 649.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 576.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1543.arff\n",
      "dict_values([['decision_tree'], 1080, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22563062886292815, 0.5300382366171841, 0.4097461328954586, 5, 0.40463339924040426, 125, 15, 0.9148148148148149, 0.9027777777777778, 0.9111111111111111])\n",
      "Nominal file 825.arff\n",
      "dict_values([['decision_tree'], 506, 20, 17, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.001976284584980237, 0.9308300395256917, 0.08857588248599396, 2, 0.6861003509699899, 49, 9, 0.9090909090909091, 0.7114624505928854, 0.8853754940711462])\n",
      "Nominal file 960.arff\n",
      "dict_values([['SVM_poly'], 90, 8, 0, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.011111111111111112, 0.9222222222222223, 0.3333333333333333, 2, 0.6011538111794036, 41, 12, 0.7666666666666667, 0.3333333333333333, 0.8666666666666667])\n",
      "Numeric file 433.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 599.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 872.arff\n",
      "dict_values([['decision_tree'], 506, 13, 11, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.03359683794466403, 0.9308300395256917, 0.2991114952401856, 2, 0.6779471359178069, 56, 14, 0.9229249011857708, 0.7687747035573123, 0.8913043478260869])\n",
      "Numeric file 29.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 171.arff\n",
      "dict_values([['SVM_poly'], 339, 17, 0, 17, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0029498525073746312, 0.9793510324483776, 0.40476190476190477, 21, 2.5256481467530074, 185, 15, 0.4808259587020649, 0.27728613569321536, 0.8053097345132744])\n",
      "Nominal file 521.arff\n",
      "dict_values([['decision_tree'], 120, 19, 4, 15, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.008333333333333333, 0.875, 0.3364309482473545, 2, 0.37677016125643675, 2, 1, 1.0, 1.0, 1.0])\n",
      "Nominal file 1001.arff\n",
      "dict_values([['decision_tree'], 76, 45, 0, 45, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013157894736842105, 0.9868421052631579, 0.18595041322314057, 2, 0.27619092240707505, 5, 4, 1.0, 1.0, 1.0])\n",
      "Nominal file 464.arff\n",
      "dict_values([['decision_tree'], 250, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.541595807747296, 0.5568626130445409, 0.5492292103959184, 2, 0.6931471805599453, 41, 13, 0.888, 0.844, 0.8599999999999999])\n",
      "Nominal file 1451.arff\n",
      "dict_values([['decision_tree'], 705, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.010131728563570907, 0.6209436966275876, 0.09914696465890827, 2, 0.29442293000974995, 45, 12, 0.9375886524822695, 0.8836879432624114, 0.9276595744680851])\n",
      "Numeric file 608.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 52.arff\n",
      "dict_values([['decision_tree'], 10, 32, 0, 32, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9655172413793104, 0.0, 0.9, 0.3333333333333333, 2, 0.6931471805599453, 3, 2, 1.0, 1.0, 1.0])\n",
      "Numeric file 1095.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 673.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 223.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 736.arff\n",
      "dict_values([['decision_tree'], 111, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24610238981496443, 0.5437363969474058, 0.4365528688607301, 2, 0.6921323091505793, 32, 11, 0.8108108108108109, 0.7027027027027027, 0.7207207207207207])\n",
      "Nominal file 448.arff\n",
      "dict_values([['SVM_poly'], 120, 3, 0, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.7, 0.12500000000000006, 2, 0.6474466390346325, 29, 13, 0.85, 0.7166666666666667, 1.0])\n",
      "Nominal file 1538.arff\n",
      "dict_values([['decision_tree'], 8753, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49472519560113903, 0.5092289096260969, 0.4999487272869559, 5, 0.28416369516462603, 749, 25, 0.9453901519479035, 0.9352222095281618, 0.9442476865074831])\n",
      "Numeric file 624.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 848.arff\n",
      "dict_values([['decision_tree'], 38, 5, 4, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.20452884666797372, 0.7894736842105263, 0.3483871343459403, 2, 0.5763341277567499, 8, 5, 0.9473684210526315, 0.7368421052631579, 0.8421052631578947])\n",
      "Nominal file 13.arff\n",
      "dict_values([['SVM_poly'], 286, 9, 0, 9, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0034965034965034965, 0.7762237762237763, 0.2093023255813954, 2, 0.6084755754298137, 93, 20, 0.7937062937062938, 0.7447552447552448, 0.9055944055944056])\n",
      "Numeric file 632.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 798.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 777.arff\n",
      "dict_values([['decision_tree'], 47, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2726451831367458, 0.6620619701982757, 0.40136995529082276, 2, 0.6820148175994905, 6, 4, 1.0, 0.8297872340425532, 0.9787234042553191])\n",
      "Numeric file 327.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 409.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 665.arff\n",
      "dict_values([['decision_tree'], 147, 6, 3, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24489795918367346, 0.7551020408163265, 0.5222539682539683, 19, 2.28819340774515, 94, 14, 0.4965986394557823, 0.14965986394557823, 0.48299319727891155])\n",
      "Nominal file 720.arff\n",
      "dict_values([['decision_tree'], 4177, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12346584011474561, 0.6067460805310956, 0.33307219257165627, 2, 0.6931407325677168, 705, 26, 0.7933923868805363, 0.7352166626765622, 0.7929135743356476])\n",
      "Numeric file 757.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 307.arff\n",
      "dict_values([['SVM_poly'], 990, 12, 10, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06666666666666667, 0.5333333333333333, 0.25504029681827656, 11, 2.3978952727983707, 148, 15, 0.5313131313131313, 0.7131313131313133, 0.9777777777777777])\n",
      "Numeric file 612.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 868.arff\n",
      "dict_values([['SVM_poly'], 100, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3191727620100508, 0.5659278602575233, 0.4774604317263625, 2, 0.6899437584583995, 14, 5, 0.99, 0.82, 1.0])\n",
      "Numeric file 33.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 491.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 887.arff\n",
      "dict_values([['decision_tree'], 61, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.21311475409836064, 0.7868852459016393, 0.5052823315118397, 2, 0.6919373402520164, 20, 12, 0.7540983606557377, 0.6557377049180327, 0.7049180327868853])\n",
      "Numeric file 700.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1559.arff\n",
      "dict_values([['SVM_poly'], 106, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4790244881573665, 0.503809869375907, 0.49676035683748015, 4, 1.271138128186509, 29, 9, 0.8207547169811321, 0.7169811320754716, 0.9528301886792453])\n",
      "Numeric file 429.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 716.arff\n",
      "dict_values([['decision_tree'], 100, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2938189506516575, 0.5670492829437206, 0.4970416723942733, 2, 0.6640641265641081, 11, 4, 1.0, 0.8599999999999999, 1.0])\n",
      "Numeric file 653.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 203.arff\n",
      "dict_values([['naive_bayes'], 189, 9, 3, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005291005291005291, 0.9365079365079365, 0.3300448432450743, 133, 4.7795054975077385, 169, 18, 0.13227513227513227, 0.8148148148148148, 0.5238095238095238])\n",
      "Nominal file 829.arff\n",
      "dict_values([['decision_tree'], 100, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4293058729353442, 0.5519169782402497, 0.4721368233265853, 2, 0.6881388137135884, 15, 6, 0.97, 0.81, 0.82])\n",
      "Nominal file 983.arff\n",
      "dict_values([['decision_tree'], 1473, 9, 2, 7, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018329938900203666, 0.9260013577732519, 0.32104158523455867, 2, 0.682456779053557, 501, 25, 0.7243720298710116, 0.6225390359809911, 0.7243720298710116])\n",
      "Numeric file 595.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 741.arff\n",
      "dict_values([['decision_tree'], 1024, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.091796875, 0.39453125, 0.2784595007183908, 2, 0.6931300143240232, 162, 12, 0.765625, 0.6611328125, 0.685546875])\n",
      "Numeric file 604.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1518.arff\n",
      "dict_values([['SVM_poly'], 47, 90, 90, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12727272727272732, 0.8684124386252046, 0.4977427056527134, 4, 1.2202272495899888, 11, 5, 0.9787234042553191, 0.9574468085106385, 1.0])\n",
      "Numeric file 487.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 25.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 891.arff\n",
      "dict_values([['SVM_poly'], 93, 6, 4, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.010752688172043012, 0.6559139784946236, 0.32532003046095237, 2, 0.667431707658747, 14, 7, 0.8924731182795699, 0.45161290322580644, 0.9032258064516129])\n",
      "Numeric file 192.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 468.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 690.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 940.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 413.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1076.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 556.arff\n",
      "dict_values([['SVM_poly'], 475, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5000000000000012, 0.22727272727272735, 178, 3.10081592872084, 273, 26, 0.5347368421052632, 0.36631578947368426, 0.6568421052631579])\n",
      "Numeric file 1099.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1563.arff\n",
      "dict_values([['naive_bayes'], 64, 229, 0, 229, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.015625, 0.984375, 0.5, 2, 0.6887461892700277, 13, 12, 0.859375, 0.984375, 0.96875])\n",
      "Numeric file 628.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 782.arff\n",
      "dict_values([['decision_tree'], 120, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49999999999999994, 0.5, 0.5, 2, 0.6918966592050799, 10, 5, 0.9833333333333333, 0.9333333333333333, 0.9416666666666667])\n",
      "Nominal file 278.arff\n",
      "dict_values([['decision_tree'], 74, 62, 62, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.9053955021061313, 0.3235705529311787, 4, 0.8566119998266046, 12, 7, 0.972972972972973, 0.6756756756756757, 0.972972972972973])\n",
      "Nominal file 444.arff\n",
      "dict_values([['SVM_poly'], 132, 3, 0, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.7272727272727273, 0.12000000000000006, 2, 0.6902748242189058, 36, 13, 0.765151515151515, 0.75, 0.9772727272727273])\n",
      "Numeric file 852.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1534.arff\n",
      "dict_values([['decision_tree'], 10190, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5020606461109901, 0.5135092386459156, 0.5065317057740194, 5, 0.20411121344517155, 502, 21, 0.9671246319921492, 0.9600588812561335, 0.9645731108930324])\n",
      "Nominal file 501.arff\n",
      "dict_values([['decision_tree'], 100, 10, 2, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01, 0.62, 0.05400496468633155, 2, 0.6640641265641081, 4, 3, 1.0, 1.0, 1.0])\n",
      "Nominal file 794.arff\n",
      "dict_values([['SVM_poly'], 250, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4097090666318998, 0.5412698102473898, 0.4955746962171736, 2, 0.6868620016589055, 26, 8, 0.94, 0.7840000000000001, 1.0])\n",
      "Nominal file 1467.arff\n",
      "dict_values([['SVM_poly'], 540, 20, 20, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4982891461971052, 0.501107823111885, 0.5000332340524347, 2, 0.29125423265214945, 36, 10, 0.9481481481481482, 0.9, 0.9981481481481481])\n",
      "Numeric file 452.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1488.arff\n",
      "dict_values([['decision_tree'], 195, 22, 22, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.07701905631688868, 0.5729625831806656, 0.27495200028851213, 2, 0.5580701289224494, 15, 6, 0.9897435897435898, 0.6974358974358974, 0.9230769230769231])\n",
      "Nominal file 844.arff\n",
      "dict_values([['SVM_poly'], 286, 9, 1, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0034965034965034965, 0.7762237762237763, 0.21218725718725717, 2, 0.6801562094176439, 117, 16, 0.6818181818181818, 0.486013986013986, 0.7482517482517482])\n",
      "Numeric file 669.arff\n",
      "Input y contains NaN.\n",
      "Nominal file 686.arff\n",
      "dict_values([['naive_bayes'], 264, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.49999999999999933, 0.11538461538461532, 263, 5.570697988142075, 263, 32, 0.05303030303030304, 1.0, 0.9507575757575758])\n",
      "Nominal file 1060.arff\n",
      "dict_values([['decision_tree'], 63, 29, 29, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06400409626216076, 0.37619206349206347, 0.16027421502120365, 2, 0.38061317843558684, 5, 3, 1.0, 0.8730158730158731, 0.9682539682539683])\n",
      "Nominal file 956.arff\n",
      "dict_values([['naive_bayes'], 106, 58, 0, 58, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009433962264150943, 0.5094339622641509, 0.1746987951807228, 2, 0.6274370336771098, 19, 8, 0.8773584905660378, 1.0, 1.0])\n",
      "Nominal file 813.arff\n",
      "dict_values([['decision_tree'], 1000, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.31331345073050904, 0.5068223731830758, 0.43842926708733554, 2, 0.6851880420827186, 91, 11, 0.902, 0.662, 0.746])\n",
      "Nominal file 48.arff\n",
      "dict_values([['decision_tree'], 151, 5, 3, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.152317880794702, 0.847682119205298, 0.4579610608040125, 3, 1.0983062060529227, 59, 13, 0.7019867549668874, 0.5165562913907285, 0.6158940397350994])\n",
      "Numeric file 540.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1061.arff\n",
      "dict_values([['decision_tree'], 107, 29, 29, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02570093457943925, 0.4806691471163706, 0.14405421219669345, 2, 0.48171993919061085, 12, 5, 0.9719626168224299, 0.8691588785046729, 0.897196261682243])\n",
      "Numeric file 404.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 957.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 812.arff\n",
      "dict_values([['SVM_poly'], 100, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4516591615800105, 0.5723398348917599, 0.5076352036995895, 2, 0.6913460990017393, 11, 6, 0.99, 0.8000000000000002, 1.0])\n",
      "Numeric file 49.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 1574.arff\n",
      "could not convert string to float: '{0 0.708333'\n",
      "Numeric file 541.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 668.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 687.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 900.arff\n",
      "dict_values([['decision_tree'], 400, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08579870699880185, 0.26484392712072546, 0.1546698718029706, 2, 0.6777555495642991, 108, 19, 0.635, 0.59, 0.625])\n",
      "Numeric file 453.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 516.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1523.arff\n",
      "dict_values([['decision_tree'], 310, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0869524296376654, 0.5144517612504481, 0.32939045692707036, 3, 1.0340787928128257, 45, 8, 0.9032258064516129, 0.8387096774193549, 0.8709677419354839])\n",
      "Nominal file 845.arff\n",
      "dict_values([['SVM_poly'], 1000, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49443977044038234, 0.5157995526195511, 0.5085436489991879, 2, 0.6929851718108113, 110, 12, 0.8459999999999999, 0.87, 0.937])\n",
      "Nominal file 795.arff\n",
      "dict_values([['decision_tree'], 662, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.422037585861405, 0.5260098221963331, 0.46378130578644505, 2, 0.6930741600989431, 218, 21, 0.5981873111782477, 0.5377643504531722, 0.5362537764350453])\n",
      "Nominal file 1470.arff\n",
      "dict_values([['SVM_poly'], 500, 12, 1, 11, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002, 0.7057199999999997, 0.07094375757575758, 2, 0.6802920001921535, 151, 24, 0.674, 0.516, 0.912])\n",
      "Nominal file 916.arff\n",
      "dict_values([['decision_tree'], 100, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2791680462220798, 0.5857139509530643, 0.46074325742999395, 2, 0.6859298002523728, 19, 8, 0.93, 0.67, 0.76])\n",
      "Nominal file 853.arff\n",
      "dict_values([['decision_tree'], 506, 13, 12, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.04054409826462902, 0.9308300395256917, 0.4251547320067032, 2, 0.6779471359178069, 56, 14, 0.9229249011857708, 0.7470355731225296, 0.9150197628458498])\n",
      "Nominal file 1535.arff\n",
      "dict_values([['decision_tree'], 9989, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5026635145434197, 0.5104007162184324, 0.5056568479450877, 5, 0.20955415721006812, 543, 24, 0.9661627790569627, 0.9598558414255681, 0.963059365301832])\n",
      "Numeric file 500.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 629.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 783.arff\n",
      "dict_values([['decision_tree'], 100, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.31229027547432736, 0.5362712619923782, 0.4771998218197192, 2, 0.6730116670092565, 14, 6, 0.97, 0.67, 0.87])\n",
      "Nominal file 941.arff\n",
      "dict_values([['SVM_poly'], 189, 9, 2, 7, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005291005291005291, 0.9365079365079365, 0.3300448432450743, 2, 0.6920129648318738, 31, 12, 0.8888888888888888, 0.8518518518518519, 0.8941798941798942])\n",
      "Numeric file 412.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1098.arff\n",
      "dict_values([['naive_bayes'], 48, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.266627145438121, 0.5865384615384616, 0.4340512035903359, 48, 3.8712010109078907, 48, 26, 0.10416666666666667, 1.0, 1.0])\n",
      "Nominal file 557.arff\n",
      "dict_values([['SVM_poly'], 475, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5000000000000012, 0.22727272727272735, 164, 2.815167185898776, 260, 23, 0.5789473684210527, 0.3410526315789474, 0.6526315789473685])\n",
      "Nominal file 804.arff\n",
      "dict_values([['SVM_poly'], 70, 7, 3, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24285714285714285, 0.5428571428571428, 0.41430525196873974, 2, 0.6927389617440811, 19, 9, 0.8571428571428571, 0.7857142857142857, 0.8857142857142857])\n",
      "Numeric file 691.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1519.arff\n",
      "dict_values([['decision_tree'], 117, 90, 90, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16387282674298606, 0.9529110498226578, 0.5967817969759719, 3, 0.9320181767661446, 14, 8, 0.9230769230769231, 0.9145299145299145, 0.8547008547008547])\n",
      "Numeric file 486.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 890.arff\n",
      "dict_values([['decision_tree'], 108, 7, 6, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.15991389478650628, 0.515927844943389, 0.34274435550032123, 2, 0.6076934238709566, 10, 7, 0.8333333333333334, 0.7037037037037037, 0.7222222222222222])\n",
      "Numeric file 193.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 469.arff\n",
      "dict_values([['SVM_poly'], 797, 4, 0, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.027603513174404015, 0.5119196988707654, 0.19047619047619047, 6, 1.7884993949883827, 236, 17, 0.2672521957340025, 0.2559598494353827, 0.45294855708908405])\n",
      "Nominal file 740.arff\n",
      "dict_values([['decision_tree'], 1000, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.28157720062023395, 0.5170780580790262, 0.46550394401911654, 2, 0.6859298002523728, 86, 13, 0.899, 0.67, 0.799])\n",
      "Numeric file 605.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 828.arff\n",
      "dict_values([['decision_tree'], 100, 100, 100, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2691217178966996, 0.5856323331652374, 0.49378776150905496, 2, 0.6913460990017393, 8, 4, 1.0, 0.89, 1.0])\n",
      "Numeric file 982.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 594.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 717.arff\n",
      "dict_values([['SVM_poly'], 508, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16120683972722571, 0.5464544464784257, 0.34744619567265983, 2, 0.6851900368105215, 46, 10, 0.9291338582677164, 0.84251968503937, 0.9311023622047244])\n",
      "Numeric file 652.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 202.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 994.arff\n",
      "dict_values([['SVM_poly'], 846, 18, 18, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12391275257593978, 0.5845646178092976, 0.35035246445251605, 2, 0.5706196572066369, 28, 8, 0.966903073286052, 0.8120567375886525, 0.983451536643026])\n",
      "Numeric file 428.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 582.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 214.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 644.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 869.arff\n",
      "dict_values([['decision_tree'], 500, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3637486008544348, 0.5032609446106011, 0.47676476071504403, 2, 0.6827430482038837, 33, 7, 0.938, 0.816, 0.836])\n",
      "Numeric file 490.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 185.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 886.arff\n",
      "dict_values([['decision_tree'], 500, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.28708333333333336, 0.6742325573682726, 0.4846664921804543, 2, 0.6931391805386118, 116, 15, 0.724, 0.598, 0.684])\n",
      "Nominal file 756.arff\n",
      "dict_values([['decision_tree'], 159, 15, 15, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19757075471698113, 0.5554058101227917, 0.4038511703523339, 2, 0.6407848608302267, 11, 5, 0.9937106918238994, 0.949685534591195, 0.9937106918238994])\n",
      "Numeric file 613.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 664.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 721.arff\n",
      "dict_values([['SVM_poly'], 200, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4425, 0.5525, 0.4945000000000001, 2, 0.6926971130356336, 36, 9, 0.925, 0.845, 0.975])\n",
      "Numeric file 408.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 633.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 799.arff\n",
      "dict_values([['SVM_poly'], 1000, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.48682990548014027, 0.5006440861774218, 0.4948050861089353, 2, 0.6931291804519437, 118, 12, 0.847, 0.884, 0.917])\n",
      "Nominal file 776.arff\n",
      "dict_values([['decision_tree'], 250, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.492506379832792, 0.51927654611926, 0.5082250720446254, 2, 0.6931471805599453, 35, 8, 0.92, 0.8759999999999999, 0.904])\n",
      "Nominal file 275.arff\n",
      "dict_values([['SVM_poly'], 71, 62, 62, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.014084507042253521, 0.9173235267778223, 0.3250626998917961, 6, 1.2386997493604233, 18, 9, 0.8591549295774648, 0.6619718309859155, 0.8873239436619719])\n",
      "Numeric file 625.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 760.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 449.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1539.arff\n",
      "dict_values([['decision_tree'], 9172, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49595895648080074, 0.5131185320918151, 0.5020332984924062, 5, 0.2803920668692545, 763, 30, 0.9465765372873964, 0.9372001744439599, 0.9452682075883122])\n",
      "Numeric file 672.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 222.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 737.arff\n",
      "dict_values([['SVM_poly'], 3107, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4150119801087785, 0.7857808977510978, 0.5412015672811054, 2, 0.6931148083609359, 439, 23, 0.7888638558094625, 0.738654650788542, 0.8683617637592533])\n",
      "Nominal file 808.arff\n",
      "dict_values([['SVM_poly'], 100, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4473159185945084, 0.5331867526689965, 0.502415264370986, 2, 0.6881388137135884, 16, 5, 0.96, 0.91, 1.0])\n",
      "Nominal file 53.arff\n",
      "dict_values([['SVM_poly'], 270, 13, 13, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.14814814814814814, 0.7246913580246909, 0.40507110079966996, 2, 0.6869615765973234, 46, 9, 0.8925925925925926, 0.8592592592592592, 0.9148148148148149])\n",
      "Numeric file 1094.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 609.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 873.arff\n",
      "dict_values([['SVM_poly'], 250, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.229811917893062, 0.5331776450813215, 0.48879281390972784, 2, 0.6838704590270674, 23, 7, 0.964, 0.772, 1.0])\n",
      "Nominal file 520.arff\n",
      "dict_values([['decision_tree'], 163, 5, 4, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08968929348901643, 0.6441717791411042, 0.4204397579587923, 17, 1.9169190942137107, 86, 14, 0.5950920245398773, 0.4233128834355828, 0.5398773006134969])\n",
      "Nominal file 465.arff\n",
      "dict_values([['decision_tree'], 97, 10, 7, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.010309278350515464, 0.681779086892489, 0.08786365689876918, 2, 0.5594859152849988, 14, 7, 0.9587628865979382, 0.9072164948453608, 0.8969072164948453])\n",
      "Nominal file 1450.arff\n",
      "dict_values([['decision_tree'], 125, 39, 39, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0656072504086959, 0.7874399999999999, 0.1780743840015911, 2, 0.6486759339353328, 24, 11, 0.888, 0.72, 0.824])\n",
      "Nominal file 936.arff\n",
      "dict_values([['decision_tree'], 500, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.276687634017199, 0.5349177806150979, 0.47134267925528306, 2, 0.6892701675539441, 49, 10, 0.912, 0.64, 0.81])\n",
      "Numeric file 577.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1542.arff\n",
      "dict_values([['decision_tree'], 1183, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.20730381100055809, 0.5249776279565493, 0.40144671649245217, 5, 0.39297192763865446, 128, 15, 0.9230769230769231, 0.9053254437869822, 0.915469146238377])\n",
      "Nominal file 824.arff\n",
      "dict_values([['decision_tree'], 500, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49044345119059907, 0.5267775388955581, 0.5089015376135775, 2, 0.6885320764504561, 44, 10, 0.912, 0.678, 0.804])\n",
      "Numeric file 961.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 432.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1057.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 648.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 832.arff\n",
      "dict_values([['SVM_poly'], 250, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2605491143090986, 0.5241591473867613, 0.4757413812920154, 2, 0.6868620016589055, 29, 11, 0.944, 0.736, 1.0])\n",
      "Numeric file 998.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1554.arff\n",
      "dict_values([['SVM_poly'], 500, 12, 8, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08, 0.838, 0.41867737187125703, 5, 1.4890015711447033, 166, 13, 0.556, 0.424, 0.7419999999999999])\n",
      "Nominal file 561.arff\n",
      "dict_values([['naive_bayes'], 209, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.004784688995215311, 0.18349839073523264, 0.046941301033756495, 104, 4.387374158632403, 151, 20, 0.20574162679425836, 0.8277511961722487, 0.3684210526315789])\n",
      "Numeric file 424.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 2.arff\n",
      "C value not in ('C ', 'H ', 'G')\n",
      "Nominal file 536.arff\n",
      "dict_values([['SVM_poly'], 559, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009040170218762699, 0.5, 0.04007577534697839, 18, 0.7989667235341976, 142, 28, 0.7906976744186046, 0.30590339892665475, 0.7960644007155635])\n",
      "Nominal file 865.arff\n",
      "dict_values([['naive_bayes'], 100, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01, 0.54, 0.024336569579288037, 2, 0.25363894692169137, 8, 7, 0.97, 1.0, 0.94])\n",
      "Nominal file 1446.arff\n",
      "dict_values([['decision_tree'], 296, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.019255211260074078, 0.6919500145306601, 0.12922693787897868, 2, 0.383292403718047, 32, 9, 0.9324324324324325, 0.8074324324324325, 0.8851351351351351])\n",
      "Nominal file 1016.arff\n",
      "dict_values([['SVM_poly'], 990, 13, 10, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06666666666666667, 0.5333333333333333, 0.2719340694514989, 2, 0.30463609734923813, 17, 7, 0.9878787878787879, 0.9414141414141414, 1.0])\n",
      "Nominal file 751.arff\n",
      "dict_values([['decision_tree'], 1000, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2737282242076835, 0.5023456693611927, 0.4449721031765005, 2, 0.6859298002523728, 83, 10, 0.899, 0.658, 0.7729999999999999])\n",
      "Numeric file 614.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 497.arff\n",
      "dict_values([['decision_tree'], 137, 7, 4, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06569343065693431, 0.9343065693430657, 0.35617880045031197, 2, 0.6039068887523177, 34, 9, 0.8467153284671532, 0.72992700729927, 0.7518248175182483])\n",
      "Nominal file 1508.arff\n",
      "dict_values([['SVM_poly'], 403, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3567085244504594, 0.481742196682774, 0.4261218057550825, 5, 1.4189430222642563, 40, 10, 0.9330024813895782, 0.8635235732009926, 0.9454094292803971])\n",
      "Numeric file 35.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 478.arff\n",
      "dict_values([['naive_bayes'], 500, 23, 20, 3, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9981343283582089, 0.0, 0.5589861857252494, 0.015444548614425567, 15, 2.5289905160861976, 15, 14, 0.566, 1.0, 1.0])\n",
      "Numeric file 706.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 213.arff\n",
      "dict_values([['naive_bayes'], 195, 11, 2, 9, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005128205128205128, 0.764102564102564, 0.04852135631952143, 177, 5.142350601415426, 187, 18, 0.10769230769230768, 1.0, 0.8615384615384615])\n",
      "Numeric file 643.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 62.arff\n",
      "dict_values([['naive_bayes'], 101, 17, 1, 16, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009900990099009901, 0.9207920792079208, 0.12484883984581666, 7, 1.6570097037423919, 10, 7, 0.8811881188118812, 1.0, 1.0])\n",
      "Numeric file 839.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 585.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 9.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 710.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 340.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 655.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 205.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1549.arff\n",
      "dict_values([['SVM_poly'], 750, 40, 37, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.260181229773463, 0.7255670731707311, 0.49843119168914624, 8, 2.0057276841098277, 276, 17, 0.39200000000000007, 0.364, 1.0])\n",
      "Numeric file 985.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 593.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 747.arff\n",
      "dict_values([['SVM_poly'], 167, 4, 0, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1317365269461078, 0.39520958083832336, 0.21052631578947367, 2, 0.5362927691098188, 15, 7, 0.9640718562874252, 0.9281437125748502, 0.9940119760479041])\n",
      "Numeric file 602.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 23.arff\n",
      "dict_values([['SVM_poly'], 1473, 9, 2, 7, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018329938900203666, 0.9260013577732519, 0.32104158523455867, 3, 1.066777482163813, 679, 21, 0.5675492192803802, 0.4378818737270876, 0.6021724372029871])\n",
      "Nominal file 878.arff\n",
      "dict_values([['decision_tree'], 100, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.384787305009276, 0.5453529053893726, 0.4849884350212211, 2, 0.6913460990017393, 15, 6, 0.96, 0.7299999999999999, 0.89])\n",
      "Numeric file 481.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 194.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 897.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 229.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 679.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 696.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 415.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1420.arff\n",
      "dict_values([['naive_bayes'], 209, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.004784688995215311, 0.18349839073523264, 0.046941301033756495, 104, 4.387374158632403, 151, 20, 0.20574162679425836, 0.8277511961722487, 0.3684210526315789])\n",
      "Numeric file 1070.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 946.arff\n",
      "dict_values([['decision_tree'], 88, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4318181818181818, 0.43394614543466387, 0.43288216362642284, 2, 0.6928888938590294, 36, 12, 0.7613636363636364, 0.5681818181818182, 0.5681818181818182])\n",
      "Nominal file 1565.arff\n",
      "dict_values([['SVM_poly'], 294, 13, 13, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.008503401360544218, 0.9272108843537428, 0.5303316215771404, 5, 1.1370218045160145, 86, 13, 0.7448979591836735, 0.3129251700680272, 0.7789115646258504])\n",
      "Numeric file 550.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 784.arff\n",
      "dict_values([['SVM_poly'], 140, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02857142857142857, 0.4160714285714286, 0.12290101984346588, 2, 0.6931471805599453, 38, 16, 0.7714285714285715, 0.6785714285714286, 0.8214285714285714])\n",
      "Nominal file 911.arff\n",
      "dict_values([['decision_tree'], 250, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.36704514902317587, 0.5342771400203041, 0.48379140147822375, 2, 0.6859298002523728, 23, 8, 0.968, 0.82, 0.792])\n",
      "Numeric file 1027.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 442.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1498.arff\n",
      "dict_values([['decision_tree'], 462, 9, 8, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.11579858644876655, 0.6169830169830168, 0.38760432473857287, 2, 0.6451389826734641, 97, 14, 0.7922077922077922, 0.7121212121212122, 0.777056277056277])\n",
      "Nominal file 1532.arff\n",
      "dict_values([['decision_tree'], 10668, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5032355771556771, 0.5132432113822457, 0.5069392268000777, 5, 0.19572627103258916, 521, 25, 0.9699100112485939, 0.9625984251968503, 0.9662542182227222])\n",
      "Nominal file 854.arff\n",
      "dict_values([['decision_tree'], 158, 7, 5, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0379746835443038, 0.5506329113924051, 0.2672062766276599, 2, 0.6724950807186254, 7, 5, 0.9936708860759493, 0.6835443037974683, 0.9746835443037974])\n",
      "Nominal file 792.arff\n",
      "dict_values([['decision_tree'], 500, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.38882602068218053, 0.5012348560882466, 0.4732721610916821, 2, 0.674600230714884, 42, 12, 0.938, 0.806, 0.734])\n",
      "Numeric file 638.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 454.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 907.arff\n",
      "dict_values([['decision_tree'], 400, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1540536037863422, 0.4562699967352266, 0.34879168207486816, 2, 0.6926971130356336, 101, 15, 0.6325, 0.54, 0.63])\n",
      "Nominal file 19.arff\n",
      "dict_values([['naive_bayes'], 107, 12, 0, 12, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009345794392523364, 0.8130841121495327, 0.059701492537313404, 7, 1.669315316818313, 32, 15, 0.7009345794392523, 1.0, 0.9626168224299065])\n",
      "Numeric file 842.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1524.arff\n",
      "dict_values([['decision_tree'], 310, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0869524296376654, 0.5144517612504481, 0.32939045692707036, 2, 0.6287993940937805, 35, 15, 0.9032258064516129, 0.7806451612903226, 0.867741935483871])\n",
      "Nominal file 511.arff\n",
      "dict_values([['naive_bayes'], 315, 13, 11, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01615450778012355, 0.8666666666666667, 0.2931257744955405, 257, 5.47190551785789, 295, 25, 0.07301587301587302, 0.8698412698412697, 0.28253968253968254])\n",
      "Nominal file 680.arff\n",
      "dict_values([['naive_bayes'], 185, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005405405405405406, 0.5360360360360361, 0.01021388919390873, 36, 3.2914886327842097, 148, 24, 0.23783783783783785, 1.0, 0.654054054054054])\n",
      "Nominal file 950.arff\n",
      "dict_values([['decision_tree'], 559, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009022844426692331, 0.5, 0.040075398699324694, 2, 0.14834683278720076, 17, 8, 0.9928443649373881, 0.8944543828264758, 0.9892665474060823])\n",
      "Nominal file 1066.arff\n",
      "dict_values([['decision_tree'], 145, 94, 94, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9148936170212766, 0.0, 0.6872413793103447, 0.1402618220861321, 2, 0.6782093939033127, 22, 7, 0.9172413793103448, 0.696551724137931, 0.8344827586206898])\n",
      "Numeric file 1436.arff\n",
      "could not convert string to float: '{0 -1'\n",
      "Numeric file 403.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1089.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 546.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 815.arff\n",
      "dict_values([['decision_tree'], 52, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3698224852071005, 0.6220735785953178, 0.49968213047579535, 2, 0.6901856760188042, 7, 4, 1.0, 0.8461538461538461, 0.9807692307692307])\n",
      "Nominal file 39.arff\n",
      "dict_values([['SVM_poly'], 336, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002976190476190476, 0.5682156385281387, 0.36529719871891647, 8, 1.517122829952031, 55, 10, 0.8869047619047619, 0.7797619047619048, 0.9017857142857143])\n",
      "Nominal file 862.arff\n",
      "dict_values([['decision_tree'], 87, 10, 8, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3218390804597701, 0.6781609195402298, 0.5227817910720657, 2, 0.6925525323607232, 21, 8, 0.8735632183908046, 0.781609195402299, 0.8390804597701149])\n",
      "Numeric file 531.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 474.arff\n",
      "dict_values([['SVM_poly'], 364, 32, 0, 32, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0027472527472527475, 0.5934065934065934, 0.17679558011049723, 6, 1.6634515269050298, 151, 19, 0.41483516483516486, 0.22802197802197802, 1.0])\n",
      "Nominal file 1441.arff\n",
      "dict_values([['decision_tree'], 123, 39, 39, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.04878048780487805, 0.8559640820288801, 0.20863300603792412, 2, 0.38654122656542195, 13, 6, 0.975609756097561, 0.8211382113821138, 0.959349593495935])\n",
      "Nominal file 1011.arff\n",
      "dict_values([['decision_tree'], 336, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002976190476190476, 0.5682156385281387, 0.36529719871891647, 2, 0.6820338129816279, 25, 8, 0.9791666666666666, 0.5863095238095238, 0.9732142857142857])\n",
      "Nominal file 927.arff\n",
      "dict_values([['SVM_poly'], 42, 16, 16, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3427100569957713, 0.5811688311688311, 0.4967934166598481, 2, 0.6748952737438281, 9, 5, 0.9285714285714286, 0.8333333333333334, 1.0])\n",
      "Numeric file 566.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1553.arff\n",
      "dict_values([['SVM_poly'], 700, 12, 8, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06142857142857143, 0.8, 0.4377174249938224, 3, 1.09684720680143, 203, 21, 0.5871428571428572, 0.44142857142857145, 0.6771428571428572])\n",
      "Nominal file 835.arff\n",
      "dict_values([['SVM_poly'], 48, 4, 0, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.5, 0.33333333333333326, 2, 0.6853142072764582, 9, 6, 0.9583333333333334, 0.875, 1.0])\n",
      "Nominal file 970.arff\n",
      "dict_values([['SVM_poly'], 841, 70, 70, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0741181133571144, 0.5091923534254083, 0.24588811390280754, 2, 0.6625423081259516, 26, 11, 0.9845422116527943, 0.990487514863258, 1.0])\n",
      "Numeric file 423.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 989.arff\n",
      "dict_values([['decision_tree'], 898, 38, 6, 32, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9166666666666666, 0.0, 0.9988864142538976, 0.31261842465749123, 2, 0.5491209782481898, 13, 6, 0.9922048997772829, 0.8608017817371938, 0.977728285077951])\n",
      "Nominal file 1545.arff\n",
      "dict_values([['decision_tree'], 1252, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19619247716210292, 0.5223505294754188, 0.3951759396096781, 5, 0.3985901241715547, 145, 17, 0.9185303514376997, 0.9041533546325878, 0.9137380191693291])\n",
      "Numeric file 570.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1115.arff\n",
      "dict_values([['SVM_poly'], 151, 6, 2, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.006622516556291391, 0.847682119205298, 0.08587233351959735, 3, 1.0983062060529227, 12, 11, 0.5960264900662252, 0.543046357615894, 0.8079470198675497])\n",
      "Numeric file 435.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 966.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 209.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 659.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 527.arff\n",
      "dict_values([['naive_bayes'], 67, 15, 15, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.014925373134328358, 0.1786518659033543, 0.030321089175692352, 67, 4.204692619390965, 67, 56, 0.07462686567164178, 1.0, 1.0])\n",
      "Nominal file 1512.arff\n",
      "dict_values([['SVM_poly'], 200, 13, 13, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01, 0.97, 0.46269078826070353, 5, 1.507281208633899, 90, 13, 0.535, 0.13, 0.705])\n",
      "Nominal file 874.arff\n",
      "dict_values([['decision_tree'], 50, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2266272189349112, 0.573764906303237, 0.438883451965725, 2, 0.6802920001921535, 2, 1, 1.0, 0.96, 0.98])\n",
      "Nominal file 931.arff\n",
      "dict_values([['decision_tree'], 662, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.42211643729926, 0.5404362618456592, 0.4636189431120557, 2, 0.6918277001413758, 202, 30, 0.6374622356495468, 0.5709969788519638, 0.5483383685800605])\n",
      "Numeric file 1007.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 462.arff\n",
      "dict_values([['naive_bayes'], 23, 5, 1, 4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.967741935483871, 0.0, 0.6956521739130435, 0.11585854538168702, 2, 0.6846162778013047, 8, 6, 0.9130434782608695, 1.0, 1.0])\n",
      "Numeric file 419.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1093.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 54.arff\n",
      "dict_values([['SVM_poly'], 846, 18, 18, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12391275257593978, 0.5845646178092976, 0.35035246445251605, 4, 1.385647492281233, 133, 18, 0.7245862884160756, 0.4728132387706856, 0.8936170212765957])\n",
      "Numeric file 675.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 730.arff\n",
      "dict_values([['decision_tree'], 250, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4823002198348686, 0.5362433516803166, 0.512470002352507, 2, 0.691994737783755, 22, 6, 0.948, 0.72, 0.756])\n",
      "Numeric file 858.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1494.arff\n",
      "dict_values([['SVM_poly'], 1055, 41, 41, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0042654028436018955, 0.6832698331540032, 0.19234778808531816, 2, 0.6393233359530519, 123, 17, 0.8511848341232228, 0.6985781990521327, 0.885308056872038])\n",
      "Nominal file 788.arff\n",
      "dict_values([['decision_tree'], 186, 60, 60, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9666666666666667, 0.0, 0.4018817204301075, 0.13438620071684593, 2, 0.678273896048092, 40, 11, 0.8172043010752688, 0.5698924731182796, 0.8118279569892473])\n",
      "Nominal file 337.arff\n",
      "dict_values([['SVM_poly'], 349, 44, 44, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2722063037249284, 0.846418338108881, 0.7290458287714903, 59, 3.673194541355576, 172, 23, 0.2836676217765043, 0.6017191977077364, 1.0])\n",
      "Nominal file 767.arff\n",
      "dict_values([['decision_tree'], 475, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5000000000000012, 0.22727272727272735, 2, 0.38337413271200516, 49, 13, 0.9515789473684211, 0.7073684210526315, 0.9452631578947368])\n",
      "Nominal file 458.arff\n",
      "dict_values([['SVM_poly'], 841, 70, 70, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0741181133571144, 0.5091923534254083, 0.24588811390280754, 4, 1.238942395008713, 32, 8, 0.9631391200951248, 0.9928656361474435, 1.0])\n",
      "Nominal file 1482.arff\n",
      "dict_values([['naive_bayes'], 340, 15, 15, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.07250521740144258, 0.9068664489208714, 0.3813118671651845, 30, 3.391000647588395, 84, 14, 0.2911764705882353, 0.8676470588235294, 0.8647058823529412])\n",
      "Nominal file 1528.arff\n",
      "dict_values([['decision_tree'], 1623, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19331735595067018, 0.4941261246473957, 0.3922298500674482, 5, 0.43939644982435166, 163, 16, 0.9242144177449169, 0.9094269870609982, 0.9168207024029574])\n",
      "Numeric file 15.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 634.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 771.arff\n",
      "dict_values([['decision_tree'], 108, 4, 2, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.5, 0.16178359931747466, 2, 0.6869615765973234, 26, 8, 0.8888888888888888, 0.7129629629629629, 0.8055555555555556])\n",
      "Numeric file 42.arff\n",
      "same-lst-sev-yrs value not in ('diff-lst-year', 'same-lst-yr', 'same-lst-two-yrs', ' same-lst-sev-yrs')\n",
      "Numeric file 663.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 726.arff\n",
      "dict_values([['decision_tree'], 100, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.34222048673765104, 0.5153890965589203, 0.4663563489666984, 2, 0.6730116670092565, 16, 8, 0.93, 0.8399999999999999, 0.8599999999999999])\n",
      "Numeric file 232.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 43.arff\n",
      "dict_values([['decision_tree'], 306, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.03594771241830065, 0.42372672339375994, 0.10722518325182032, 2, 0.5779217946828968, 98, 21, 0.8039215686274509, 0.6601307189542484, 0.761437908496732])\n",
      "Nominal file 818.arff\n",
      "dict_values([['decision_tree'], 310, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05806451612903226, 0.5943063422223299, 0.2719087125139848, 2, 0.6910645689482917, 2, 1, 1.0, 0.8548387096774194, 0.9741935483870968])\n",
      "Numeric file 635.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1600.arff\n",
      "dict_values([['SVM_poly'], 267, 44, 44, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5856411879516801, 0.8481005885500262, 0.7315219549329798, 2, 0.5085984133880677, 28, 8, 0.9138576779026218, 0.6928838951310862, 0.9925093632958801])\n",
      "Nominal file 770.arff\n",
      "dict_values([['decision_tree'], 625, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.04318605714285722, 0.5030588235294107, 0.3344288612341739, 2, 0.6931151802186033, 31, 7, 0.9103999999999999, 0.6256, 0.7184])\n",
      "Nominal file 459.arff\n",
      "dict_values([['decision_tree'], 83, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.40963855421686746, 0.5903614457831325, 0.4867202141900938, 3, 0.8892753337649838, 32, 9, 0.8433734939759037, 0.7469879518072289, 0.783132530120482])\n",
      "Nominal file 1529.arff\n",
      "dict_values([['decision_tree'], 1521, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19990644776071753, 0.4916657387966317, 0.3936727526849008, 5, 0.46204065332015376, 159, 16, 0.915844838921762, 0.9053254437869822, 0.9092702169625246])\n",
      "Nominal file 789.arff\n",
      "dict_values([['decision_tree'], 100, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.46416311723234593, 0.5502039828140597, 0.5184448625215592, 2, 0.6913460990017393, 14, 6, 0.96, 0.76, 0.89])\n",
      "Numeric file 623.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 336.arff\n",
      "dict_values([['SVM_poly'], 267, 22, 0, 22, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.13108614232209737, 0.8689138576779026, 0.5, 2, 0.6775728843296498, 93, 17, 0.797752808988764, 0.704119850187266, 0.9101123595505618])\n",
      "Nominal file 859.arff\n",
      "dict_values([['decision_tree'], 74, 9, 8, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.716652136006975, 0.040326987874669325, 2, 0.6799406565303493, 4, 3, 1.0, 1.0, 0.9324324324324325])\n",
      "Nominal file 1495.arff\n",
      "dict_values([['decision_tree'], 250, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.224, 0.476, 0.33333333333333326, 2, 0.6827430482038837, 4, 3, 1.0, 0.984, 1.0])\n",
      "Numeric file 674.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 224.arff\n",
      "dict_values([['SVM_poly'], 286, 9, 2, 7, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0034965034965034965, 0.7762237762237763, 0.21218725718725717, 23, 2.4171122603421544, 208, 17, 0.3076923076923077, 0.21328671328671328, 0.6013986013986014])\n",
      "Nominal file 731.arff\n",
      "dict_values([['decision_tree'], 96, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3801853267640729, 0.6947674418604657, 0.49388187618051166, 2, 0.6929301509699878, 24, 8, 0.8541666666666666, 0.7604166666666666, 0.7708333333333333])\n",
      "Numeric file 1092.arff\n",
      "String attributes not supported yet, sorry\n",
      "Numeric file 55.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 526.arff\n",
      "dict_values([['naive_bayes'], 132, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22386814574314567, 0.5, 0.3447736291486291, 97, 4.476973634657068, 125, 16, 0.16666666666666666, 0.7272727272727273, 0.22727272727272727])\n",
      "Nominal file 1513.arff\n",
      "dict_values([['SVM_poly'], 123, 12, 12, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.032520325203252036, 0.9186991869918699, 0.5154916715300771, 5, 1.369584024001329, 60, 13, 0.6585365853658537, 0.13008130081300814, 0.7479674796747967])\n",
      "Nominal file 875.arff\n",
      "dict_values([['SVM_poly'], 100, 3, 0, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1, 0.5, 0.17647058823529416, 2, 0.4862229646617922, 21, 7, 0.93, 0.89, 1.0])\n",
      "Nominal file 1006.arff\n",
      "dict_values([['SVM_poly'], 148, 18, 3, 15, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.9527027027027027, 0.3351098058544867, 2, 0.6886664154690998, 22, 7, 0.9324324324324325, 0.6959459459459459, 1.0])\n",
      "Nominal file 199.arff\n",
      "dict_values([['naive_bayes'], 125, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.6031999999999997, 0.38935061728395054, 47, 3.66459315074787, 108, 14, 0.232, 0.256, 0.168])\n",
      "Nominal file 1456.arff\n",
      "dict_values([['decision_tree'], 106, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16915094339622638, 0.6821037735849055, 0.4179123989218328, 2, 0.49777562247179563, 14, 7, 0.9528301886792453, 0.8584905660377359, 0.8962264150943396])\n",
      "Nominal file 463.arff\n",
      "dict_values([['SVM_poly'], 180, 32, 6, 26, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005555555555555556, 0.9944444444444445, 0.371764739161283, 2, 0.40294135786694235, 29, 9, 0.9333333333333333, 0.35, 0.9611111111111111])\n",
      "Numeric file 208.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 658.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 988.arff\n",
      "dict_values([['decision_tree'], 67, 15, 14, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.029850746268656712, 0.7164179104477612, 0.14779285288675106, 2, 0.6678722503844712, 11, 7, 0.9253731343283582, 0.7313432835820896, 0.746268656716418])\n",
      "Nominal file 1544.arff\n",
      "dict_values([['decision_tree'], 1277, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1954023666473469, 0.5262799340692651, 0.3988821539770506, 5, 0.38940525520932934, 143, 16, 0.9271730618637432, 0.9060297572435395, 0.9162098668754893])\n",
      "Numeric file 434.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1051.arff\n",
      "could not convert string to float: '278                           %\\tinstance number:\\t1'\n",
      "Numeric file 967.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 567.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1552.arff\n",
      "dict_values([['SVM_poly'], 1100, 12, 8, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.13454545454545455, 0.7109090909090909, 0.4242064129355552, 5, 1.580832712515842, 450, 17, 0.42818181818181816, 0.3654545454545454, 0.6181818181818182])\n",
      "Numeric file 4.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1047.arff\n",
      "dict_values([['naive_bayes'], 203, 16, 3, 13, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0049261083743842365, 0.5960591133004927, 0.03449835719700636, 11, 1.3427331228624637, 32, 11, 0.8866995073891626, 1.0, 0.9901477832512315])\n",
      "Numeric file 619.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 863.arff\n",
      "dict_values([['decision_tree'], 250, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.27473838203149265, 0.5340881197414059, 0.46611955451385717, 2, 0.6910977801629237, 32, 8, 0.912, 0.664, 0.8000000000000002])\n",
      "Numeric file 530.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 475.arff\n",
      "dict_values([['SVM_poly'], 400, 5, 1, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5, 0.27777777777777785, 73, 3.1198564656473695, 313, 13, 0.315, 0.2275, 0.885])\n",
      "Numeric file 1010.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 926.arff\n",
      "dict_values([['SVM_poly'], 500, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.47914980577033706, 0.5331618721355704, 0.499035499422313, 2, 0.6929471672244782, 54, 10, 0.85, 0.858, 1.0])\n",
      "Nominal file 951.arff\n",
      "dict_values([['decision_tree'], 559, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009040170218762699, 0.5, 0.04007577534697839, 2, 0.11045304667259806, 2, 1, 1.0, 1.0, 1.0])\n",
      "Nominal file 1067.arff\n",
      "dict_values([['SVM_poly'], 2109, 21, 21, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0110636952742216, 0.2062614534876309, 0.059307590369875485, 2, 0.4305645508080653, 262, 20, 0.8724513987671882, 0.825035561877667, 0.878615457562826])\n",
      "Numeric file 402.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 547.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1572.arff\n",
      "could not convert string to float: '{0 -1'\n",
      "Nominal file 814.arff\n",
      "dict_values([['decision_tree'], 468, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4999999999999999, 0.5, 0.49999999999999994, 2, 0.6887210394705642, 84, 13, 0.8162393162393162, 0.7905982905982905, 0.6645299145299145])\n",
      "Numeric file 681.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 455.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1460.arff\n",
      "dict_values([['decision_tree'], 5300, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.42831856072901864, 0.5237314824112557, 0.47602502157013715, 2, 0.6877922253799458, 608, 37, 0.8584905660377359, 0.6139622641509433, 0.5650943396226416])\n",
      "Numeric file 1030.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 906.arff\n",
      "dict_values([['SVM_poly'], 400, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.40485759231660867, 0.7074490308830618, 0.5189132671095871, 2, 0.6925345554465463, 103, 16, 0.655, 0.565, 0.66])\n",
      "Nominal file 18.arff\n",
      "dict_values([['SVM_poly'], 2000, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.14269999999999883, 0.4318956385465354, 0.2921223922510213, 10, 2.3025850929940455, 516, 36, 0.6665, 0.6015, 0.7595])\n",
      "Nominal file 1525.arff\n",
      "dict_values([['decision_tree'], 5456, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0732337435339132, 0.176538694379982, 0.1248862189569476, 4, 1.1884928509974293, 4, 3, 1.0, 0.906524926686217, 0.9556451612903226])\n",
      "Numeric file 510.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 793.arff\n",
      "dict_values([['decision_tree'], 250, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.23424714286732315, 0.5371711030623458, 0.4673995678377775, 2, 0.6899437584583995, 23, 7, 0.968, 0.692, 0.856])\n",
      "Numeric file 639.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 910.arff\n",
      "dict_values([['decision_tree'], 1000, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4883535164242786, 0.5212442853525218, 0.5026153615756054, 2, 0.6849326630370529, 88, 10, 0.891, 0.704, 0.7810000000000001])\n",
      "Nominal file 1026.arff\n",
      "dict_values([['SVM_poly'], 155, 8, 2, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01935483870967742, 0.7935483870967742, 0.14412186379928318, 2, 0.6239171260592478, 40, 11, 0.8709677419354839, 0.6064516129032258, 0.896774193548387])\n",
      "Numeric file 443.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1499.arff\n",
      "dict_values([['SVM_poly'], 210, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3816329626416873, 0.5707674358309562, 0.4421524746317417, 3, 1.0986122886681096, 16, 6, 0.9571428571428572, 0.9095238095238095, 0.9714285714285714])\n",
      "Numeric file 506.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1533.arff\n",
      "dict_values([['decision_tree'], 10386, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5020730061559289, 0.5129534121904589, 0.50633108600423, 5, 0.19881300891054665, 519, 21, 0.9680338917773926, 0.9617754669747738, 0.9652416714808396])\n",
      "Nominal file 855.arff\n",
      "dict_values([['decision_tree'], 500, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22700462540989855, 0.5263005334128011, 0.44834731001761385, 2, 0.6877293893152671, 52, 9, 0.886, 0.67, 0.816])\n",
      "Nominal file 785.arff\n",
      "dict_values([['decision_tree'], 45, 46, 46, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22541052379240084, 0.6544042307056691, 0.4510721140279865, 2, 0.6929002466535776, 4, 2, 1.0, 0.9555555555555556, 1.0])\n",
      "Numeric file 414.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1071.arff\n",
      "dict_values([['decision_tree'], 403, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.021401985111662532, 0.8183404684645377, 0.15923000046711713, 2, 0.2711893730418441, 32, 11, 0.967741935483871, 0.8312655086848635, 0.9528535980148883])\n",
      "Nominal file 947.arff\n",
      "dict_values([['decision_tree'], 559, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009040170218762699, 0.5, 0.04007577534697839, 2, 0.17715841498387513, 27, 9, 0.9838998211091234, 0.8336314847942755, 0.9803220035778175])\n",
      "Nominal file 59.arff\n",
      "dict_values([['SVM_poly'], 351, 34, 34, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9705882352941176, 0.0, 0.8917378917378918, 0.607550526646556, 2, 0.652825793916348, 23, 8, 0.9344729344729344, 0.8917378917378918, 0.9857549857549858])\n",
      "Numeric file 802.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1564.arff\n",
      "dict_values([['naive_bayes'], 64, 242, 0, 242, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.015625, 0.984375, 0.5, 2, 0.6887461892700277, 13, 8, 0.875, 0.984375, 0.984375])\n",
      "Nominal file 551.arff\n",
      "dict_values([['SVM_poly'], 108, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.5, 0.16178359931747466, 26, 3.102095793163505, 86, 16, 0.2777777777777778, 0.24074074074074073, 0.3425925925925926])\n",
      "Numeric file 228.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 678.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 697.arff\n",
      "dict_values([['naive_bayes'], 46, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.34210526315789475, 0.5652173913043478, 0.4662471395881007, 46, 3.828641396489094, 46, 16, 0.2826086956521739, 1.0, 1.0])\n",
      "Nominal file 879.arff\n",
      "dict_values([['SVM_poly'], 500, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.40228711654914984, 0.5213733079375193, 0.5003959430473306, 2, 0.6696343095488462, 46, 11, 0.91, 0.738, 0.984])\n",
      "Nominal file 480.arff\n",
      "dict_values([['decision_tree'], 61, 18, 10, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01639344262295082, 0.7540983606557377, 0.17225634542202312, 4, 0.9916994456908711, 4, 3, 1.0, 1.0, 1.0])\n",
      "Nominal file 195.arff\n",
      "dict_values([['naive_bayes'], 159, 15, 15, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018867924528301886, 0.5554058101227917, 0.3255298871982127, 145, 4.946840547782002, 147, 23, 0.10062893081761007, 0.9748427672955975, 0.7295597484276729])\n",
      "Nominal file 896.arff\n",
      "dict_values([['SVM_poly'], 500, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.27387086638500485, 0.5279287560043109, 0.4865976105161201, 2, 0.6859298002523728, 44, 11, 0.904, 0.686, 0.978])\n",
      "Nominal file 746.arff\n",
      "dict_values([['SVM_poly'], 250, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4670441161990048, 0.5488894009483934, 0.49416892871920304, 2, 0.6827430482038837, 20, 8, 0.956, 0.712, 1.0])\n",
      "Numeric file 603.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 984.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 438.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 711.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 654.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 204.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 992.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 838.arff\n",
      "dict_values([['SVM_poly'], 500, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2880889713560783, 0.5219065685877117, 0.48007532794309077, 2, 0.6838704590270674, 44, 10, 0.93, 0.722, 0.966])\n",
      "Numeric file 584.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 8.arff\n",
      "dict_values([['decision_tree'], 345, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.11398649990073437, 0.6620900076277652, 0.2977290838600521, 2, 0.6803853852615318, 79, 9, 0.791304347826087, 0.5594202898550724, 0.7565217391304349])\n",
      "Numeric file 707.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 212.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 642.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 34.arff\n",
      "dict_values([['SVM_poly'], 90, 8, 0, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.011111111111111112, 0.9222222222222223, 0.3333333333333333, 3, 0.6794974078359364, 39, 12, 0.7666666666666667, 0.3, 0.8555555555555555])\n",
      "Nominal file 880.arff\n",
      "dict_values([['decision_tree'], 284, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.03345096703523124, 0.5001244214403028, 0.20231549085699352, 2, 0.6931471805599453, 2, 1, 1.0, 0.8028169014084506, 0.9929577464788732])\n",
      "Nominal file 183.arff\n",
      "dict_values([['decision_tree'], 4177, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12346584011474561, 0.6067460805310956, 0.33307219257165627, 28, 2.4967210987315887, 2233, 29, 0.2820205889394302, 0.1031841034235097, 0.27531721331098874])\n",
      "Nominal file 479.arff\n",
      "dict_values([['decision_tree'], 92, 10, 6, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.010869565217391304, 0.626283260869565, 0.08773703011283344, 2, 0.5093116226143128, 12, 7, 0.9782608695652174, 0.9130434782608695, 0.9782608695652174])\n",
      "Nominal file 750.arff\n",
      "dict_values([['decision_tree'], 500, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.30324999999999974, 0.7054224692107662, 0.4995434973045484, 2, 0.6930191750980527, 127, 21, 0.666, 0.568, 0.622])\n",
      "Numeric file 615.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 817.arff\n",
      "dict_values([['decision_tree'], 48, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4761904761904762, 0.5638586956521738, 0.5251843944099378, 2, 0.6922788736563188, 15, 6, 0.9166666666666666, 0.7708333333333333, 0.8333333333333334])\n",
      "Nominal file 1121.arff\n",
      "dict_values([['decision_tree'], 294, 11, 8, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09183673469387756, 0.9081632653061225, 0.37202637404168015, 2, 0.5982695885852573, 2, 1, 1.0, 1.0, 1.0])\n",
      "Numeric file 544.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1571.arff\n",
      "could not convert string to float: '{0 0.747253'\n",
      "Nominal file 1064.arff\n",
      "dict_values([['decision_tree'], 101, 29, 29, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018650684357775876, 0.5184992183428869, 0.16034539560271965, 2, 0.42012427432309296, 17, 8, 0.9603960396039604, 0.8712871287128713, 0.9207920792079208])\n",
      "Nominal file 952.arff\n",
      "dict_values([['SVM_poly'], 214, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05557039014982941, 0.5978914722228007, 0.30662137944725815, 6, 1.5086584002236942, 50, 12, 0.766355140186916, 0.5514018691588785, 0.794392523364486])\n",
      "Nominal file 728.arff\n",
      "dict_values([['decision_tree'], 4052, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009894103921744597, 0.5528134254689059, 0.2495448776297742, 2, 0.5506585440736059, 49, 11, 0.9933366238894373, 0.950888450148075, 0.9846989141164857])\n",
      "Numeric file 682.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 1526.arff\n",
      "dict_values([['decision_tree'], 5456, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0732337435339132, 0.25115723623236175, 0.17415799499842508, 4, 1.1884928509974293, 4, 3, 1.0, 0.8924120234604106, 0.9600439882697948])\n",
      "Nominal file 513.arff\n",
      "dict_values([['decision_tree'], 559, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009022844426692331, 0.5, 0.040075398699324694, 18, 0.7356204457833756, 146, 22, 0.8264758497316635, 0.259391771019678, 0.8193202146690519])\n",
      "Numeric file 840.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 905.arff\n",
      "dict_values([['decision_tree'], 39, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02564102564102564, 0.08758000241516727, 0.02766943252238722, 2, 0.6172417697303416, 6, 4, 1.0, 1.0, 1.0])\n",
      "Nominal file 456.arff\n",
      "dict_values([['SVM_poly'], 365, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.019178082191780823, 0.5584903925714813, 0.05814750892207918, 7, 1.945887732717648, 203, 42, 0.3890410958904109, 0.28493150684931506, 1.0])\n",
      "Nominal file 1463.arff\n",
      "dict_values([['SVM_poly'], 100, 5, 0, 5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.07, 0.86, 0.3333333333333333, 2, 0.6268694575724263, 21, 8, 0.8599999999999999, 0.81, 0.92])\n",
      "Nominal file 285.arff\n",
      "dict_values([['naive_bayes'], 194, 29, 2, 27, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005154639175257732, 0.9432989690721649, 0.08616029508022038, 8, 1.609268324711428, 55, 13, 0.6752577319587629, 1.0, 0.9072164948453608])\n",
      "Nominal file 790.arff\n",
      "dict_values([['decision_tree'], 55, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.07272727272727272, 0.5421487603305786, 0.11862682771773682, 2, 0.6850259985526486, 7, 6, 0.9454545454545454, 0.8363636363636363, 0.8909090909090909])\n",
      "Nominal file 1530.arff\n",
      "dict_values([['decision_tree'], 1515, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19689725649299192, 0.4931178803364218, 0.3936105172680817, 5, 0.4585637895523763, 167, 17, 0.9161716171617161, 0.9042904290429042, 0.9075907590759076])\n",
      "Nominal file 1025.arff\n",
      "dict_values([['SVM_poly'], 400, 5, 0, 5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5, 0.27777777777777785, 2, 0.5331638407372986, 58, 11, 0.9, 0.7, 0.9825])\n",
      "Numeric file 440.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 913.arff\n",
      "dict_values([['decision_tree'], 1000, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3669561844861236, 0.5161058079188378, 0.48710074704607154, 2, 0.6802920001921535, 70, 11, 0.912, 0.8000000000000002, 0.817])\n",
      "Nominal file 769.arff\n",
      "dict_values([['SVM_poly'], 250, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4559666436530975, 0.5365163996913545, 0.5022767479184708, 2, 0.6885320764504561, 23, 7, 0.96, 0.804, 1.0])\n",
      "Nominal file 339.arff\n",
      "dict_values([['decision_tree'], 36, 22, 21, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.96, 0.0, 0.6111111111111112, 0.3745008665494764, 3, 1.0986122886681096, 5, 4, 1.0, 0.8611111111111112, 1.0])\n",
      "Numeric file 786.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 552.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 801.arff\n",
      "dict_values([['naive_bayes'], 185, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005405405405405406, 0.5360360360360361, 0.01021388919390873, 2, 0.691378423820677, 55, 29, 0.7351351351351352, 1.0, 0.8324324324324325])\n",
      "Numeric file 944.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 417.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1072.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 694.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 895.arff\n",
      "dict_values([['decision_tree'], 222, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5135135135135134, 0.5360360360360359, 0.5247747747747746, 2, 0.6715234500366745, 46, 12, 0.9144144144144143, 0.8918918918918919, 0.8828828828828829])\n",
      "Numeric file 196.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1009.arff\n",
      "dict_values([['SVM_poly'], 63, 31, 27, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.04490874959734302, 0.5714285714285714, 0.2733715162735697, 2, 0.671703461450141, 11, 8, 0.9523809523809523, 0.7619047619047619, 1.0])\n",
      "Numeric file 529.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 483.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 21.arff\n",
      "dict_values([['SVM_poly'], 1728, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.3333333333333333, 0.28571428571428564, 4, 0.8357559538495527, 101, 13, 0.8055555555555556, 0.8026620370370371, 1.0])\n",
      "Numeric file 600.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 745.arff\n",
      "dict_values([['decision_tree'], 159, 15, 14, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018867924528301886, 0.5554058101227917, 0.3255298871982127, 2, 0.6407848608302267, 11, 5, 0.9937106918238994, 0.9433962264150944, 0.9748427672955975])\n",
      "Numeric file 591.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 968.arff\n",
      "dict_values([['SVM_poly'], 365, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.019178082191780823, 0.5584903925714813, 0.05814750892207918, 2, 0.41430155628161214, 31, 14, 0.9068493150684932, 0.8191780821917808, 0.958904109589041])\n",
      "Nominal file 987.arff\n",
      "dict_values([['decision_tree'], 500, 23, 20, 3, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9981343283582089, 0.0, 0.5589861857252494, 0.015444548614425567, 2, 0.439669879401343, 2, 1, 1.0, 1.0, 1.0])\n",
      "Numeric file 657.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 207.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 712.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 342.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 587.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1048.arff\n",
      "Error while parsing header, error was: Error parsing line  @relation jEdit:Metrics/4-2-final/:BugCount/4-2-final_4-3-pre12/\n",
      "\n",
      "Numeric file 568.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 991.arff\n",
      "dict_values([['SVM_poly'], 1728, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.3333333333333333, 0.28571428571428564, 2, 0.610668040691973, 57, 13, 0.8831018518518519, 0.8553240740740741, 1.0])\n",
      "Numeric file 211.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 641.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 704.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 929.arff\n",
      "dict_values([['decision_tree'], 70, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4321804011432603, 0.5000000000000001, 0.4564684132929352, 2, 0.6931471805599453, 22, 10, 0.8142857142857143, 0.6857142857142857, 0.6857142857142857])\n",
      "Nominal file 37.arff\n",
      "dict_values([['SVM_poly'], 768, 8, 8, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09432562549251379, 0.6075102072864326, 0.3188595460371789, 2, 0.6467994206632901, 130, 13, 0.7916666666666666, 0.7630208333333334, 0.8033854166666666])\n",
      "Numeric file 495.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 753.arff\n",
      "dict_values([['SVM_poly'], 194, 32, 32, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.118938526155021, 0.5719613746283098, 0.3115317410082024, 2, 0.6905410258652528, 34, 10, 0.8041237113402062, 0.654639175257732, 0.8298969072164948])\n",
      "Nominal file 724.arff\n",
      "dict_values([['SVM_poly'], 468, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.5, 0.18181818181818182, 2, 0.6869615765973234, 83, 16, 0.7350427350427351, 0.6581196581196581, 0.8034188034188035])\n",
      "Numeric file 231.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 661.arff\n",
      "dict_values([['naive_bayes'], 34, 8, 6, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08823529411764706, 0.7941176470588235, 0.4165570675428721, 31, 3.4040404339291137, 32, 10, 0.5, 0.9705882352941176, 0.8823529411764706])\n",
      "Nominal file 40.arff\n",
      "dict_values([['SVM_poly'], 208, 60, 60, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.11434214857895311, 0.6871045358675362, 0.3489402240397241, 2, 0.6908803044104659, 23, 7, 0.9567307692307693, 0.7307692307692306, 1.0])\n",
      "Numeric file 1438.arff\n",
      "string index out of range\n",
      "Nominal file 1068.arff\n",
      "dict_values([['decision_tree'], 1109, 21, 21, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.006734895799049605, 0.1255884139047864, 0.03779642124870484, 2, 0.25216701728943836, 76, 16, 0.9477006311992786, 0.8899909828674482, 0.9477006311992786])\n",
      "Nominal file 773.arff\n",
      "dict_values([['SVM_poly'], 250, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4671598282496488, 0.5456775059097473, 0.5063406730597623, 2, 0.6931151802186033, 34, 10, 0.888, 0.8759999999999999, 1.0])\n",
      "Numeric file 636.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 17.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1480.arff\n",
      "dict_values([['decision_tree'], 583, 10, 9, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.020311202719039887, 0.7564322469982847, 0.2768058540904331, 2, 0.5989418433963181, 118, 20, 0.7495711835334476, 0.5574614065180102, 0.7135506003430532])\n",
      "Nominal file 909.arff\n",
      "dict_values([['SVM_poly'], 400, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.17861617013467118, 0.42519128997474565, 0.31087772519758555, 2, 0.6930346763408155, 88, 18, 0.6525, 0.54, 0.66])\n",
      "Nominal file 335.arff\n",
      "dict_values([['SVM_poly'], 554, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24548736462093862, 0.51985559566787, 0.35294117647058826, 2, 0.6931211145695435, 221, 11, 0.5379061371841155, 0.51985559566787, 0.5631768953068592])\n",
      "Nominal file 765.arff\n",
      "dict_values([['decision_tree'], 475, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.5000000000000012, 0.22727272727272735, 2, 0.39529305983891194, 48, 13, 0.9494736842105264, 0.6505263157894737, 0.9494736842105264])\n",
      "Numeric file 1245.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 509.arff\n",
      "dict_values([['naive_bayes'], 329, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05466079583864398, 0.5387981649644134, 0.3174452122533126, 329, 5.796057750765373, 329, 317, 0.015197568389057751, 1.0, 1.0])\n",
      "Numeric file 1029.arff\n",
      "Error while parsing header, error was: 'utf-8' codec can't decode byte 0xd5 in position 852: invalid continuation byte\n",
      "Nominal file 732.arff\n",
      "dict_values([['SVM_poly'], 250, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.46139886056762136, 0.5456589417486171, 0.4986479951657134, 2, 0.6910977801629237, 27, 7, 0.892, 0.912, 1.0])\n",
      "Numeric file 698.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 56.arff\n",
      "dict_values([['SVM_poly'], 435, 16, 0, 16, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.016091954022988506, 0.6252873563218391, 0.3333333333333333, 2, 0.667021110783824, 27, 10, 0.9816091954022989, 0.9494252873563218, 0.9954022988505747])\n",
      "Nominal file 1091.arff\n",
      "dict_values([['naive_bayes'], 59, 16, 16, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01694915254237288, 0.6779661016949154, 0.08908107083854641, 30, 3.181864041746457, 30, 13, 0.5932203389830508, 1.0, 0.7966101694915254])\n",
      "Nominal file 948.arff\n",
      "dict_values([['decision_tree'], 2178, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.11335360254428978, 0.6525025967072555, 0.4268654081510934, 2, 0.6870636031644224, 741, 33, 0.5780532598714417, 0.5606060606060606, 0.559228650137741])\n",
      "Nominal file 749.arff\n",
      "dict_values([['decision_tree'], 500, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2747534443845349, 0.4986986814078711, 0.41161968195414567, 2, 0.6917945705986355, 50, 8, 0.914, 0.646, 0.736])\n",
      "Nominal file 1005.arff\n",
      "dict_values([['decision_tree'], 214, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05557039014982938, 0.5978914722228003, 0.3066213794472581, 2, 0.6505706766412187, 33, 10, 0.8644859813084113, 0.602803738317757, 0.808411214953271])\n",
      "Nominal file 1455.arff\n",
      "dict_values([['decision_tree'], 120, 6, 1, 5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24166666666666667, 0.7583333333333333, 0.5033964646464647, 2, 0.6791932659915256, 3, 2, 1.0, 1.0, 1.0])\n",
      "Nominal file 460.arff\n",
      "dict_values([['naive_bayes'], 379, 8, 0, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002638522427440633, 0.8390501319261213, 0.01965601965601967, 4, 1.3387070473601588, 196, 35, 0.44854881266490765, 1.0, 0.7704485488126649])\n",
      "Nominal file 933.arff\n",
      "dict_values([['SVM_poly'], 250, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.276363580394832, 0.524621803952145, 0.47852405442686496, 2, 0.6892701675539441, 28, 8, 0.928, 0.74, 1.0])\n",
      "Numeric file 899.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 876.arff\n",
      "dict_values([['SVM_poly'], 100, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4357037904693316, 0.5713447895964873, 0.49991050315701313, 2, 0.6859298002523728, 12, 5, 0.98, 0.8399999999999999, 1.0])\n",
      "Numeric file 525.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1510.arff\n",
      "dict_values([['SVM_poly'], 569, 30, 30, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06263579446713657, 0.40413784603186037, 0.23891222190362163, 2, 0.6603163491952275, 22, 7, 0.9824253075571178, 0.9402460456942003, 0.9859402460456942])\n",
      "Nominal file 964.arff\n",
      "dict_values([['decision_tree'], 36, 22, 21, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.96, 0.0, 0.6111111111111112, 0.3745008665494764, 2, 0.6365141682948128, 4, 3, 1.0, 0.8888888888888888, 1.0])\n",
      "Numeric file 437.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1547.arff\n",
      "dict_values([['SVM_poly'], 1000, 20, 20, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.219, 0.704, 0.4680000000000001, 2, 0.5720083476575564, 285, 14, 0.798, 0.726, 0.892])\n",
      "Nominal file 1117.arff\n",
      "dict_values([['decision_tree'], 81, 12, 12, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19237020783001227, 0.6370370370370368, 0.38270910657552976, 3, 0.9424090214607863, 19, 7, 0.9382716049382716, 0.7654320987654321, 0.9259259259259259])\n",
      "Numeric file 1228.arff\n",
      "'Well diff' value not in ('Poorly diff', 'Intermediate', 'Well diff')\n",
      "Numeric file 708.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 421.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 7.arff\n",
      "dict_values([['SVM_poly'], 226, 69, 0, 69, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.004424778761061947, 0.995575221238938, 0.4285714285714282, 24, 2.3719127679399445, 51, 13, 0.7654867256637168, 0.8982300884955752, 0.9690265486725663])\n",
      "Numeric file 972.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1551.arff\n",
      "dict_values([['SVM_poly'], 400, 40, 37, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2696951219512195, 0.7328793626707131, 0.499389694693721, 8, 1.9193041845342318, 128, 14, 0.5, 0.4925, 1.0])\n",
      "Nominal file 925.arff\n",
      "dict_values([['SVM_poly'], 323, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.47694058313590487, 0.5675526380021328, 0.5129599171013691, 2, 0.6896493450378145, 19, 9, 0.9597523219814241, 0.9504643962848297, 0.9628482972136223])\n",
      "Nominal file 476.arff\n",
      "dict_values([['decision_tree'], 50, 6, 5, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02, 0.779503793315563, 0.06450437046396917, 2, 0.6931471805599453, 6, 4, 1.0, 1.0, 1.0])\n",
      "Nominal file 1443.arff\n",
      "dict_values([['decision_tree'], 661, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01181708373938423, 0.6207663095495387, 0.09962083181225691, 2, 0.27550573334402895, 47, 14, 0.9485627836611196, 0.8880484114977307, 0.9349470499243571])\n",
      "Nominal file 1013.arff\n",
      "dict_values([['decision_tree'], 138, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08695652173913043, 0.6521739130434783, 0.3979037267080746, 2, 0.2410883129928447, 11, 7, 0.9347826086956522, 0.15217391304347827, 0.9347826086956522])\n",
      "Nominal file 1506.arff\n",
      "dict_values([['decision_tree'], 470, 16, 3, 13, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002127659574468085, 0.9957446808510638, 0.379743993807362, 2, 0.42085932068995974, 86, 18, 0.8765957446808512, 0.16808510638297872, 0.8765957446808512])\n",
      "Nominal file 533.arff\n",
      "dict_values([['decision_tree'], 559, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009022844426692331, 0.5, 0.040075398699324694, 14, 0.5866668723632883, 114, 16, 0.8711985688729875, 0.4293381037567084, 0.8658318425760286])\n",
      "Nominal file 163.arff\n",
      "dict_values([['decision_tree'], 32, 56, 0, 56, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.03125, 0.96875, 0.35, 2, 0.5941300227248385, 6, 4, 1.0, 0.96875, 1.0])\n",
      "Nominal file 860.arff\n",
      "dict_values([['decision_tree'], 380, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3849122807017547, 0.5263157894736845, 0.4556140350877196, 2, 0.69280088019564, 28, 6, 0.85, 0.8421052631578947, 0.85])\n",
      "Nominal file 924.arff\n",
      "dict_values([['naive_bayes'], 130, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.007692307692307693, 0.5987937062937063, 0.015899952320406842, 2, 0.6931471805599453, 16, 9, 0.9307692307692308, 1.0, 0.9846153846153847])\n",
      "Nominal file 477.arff\n",
      "dict_values([['decision_tree'], 67, 16, 14, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.014925373134328358, 0.7164179104477612, 0.049825688504820255, 3, 0.25971762493319156, 5, 4, 1.0, 1.0, 0.9402985074626865])\n",
      "Nominal file 1442.arff\n",
      "dict_values([['decision_tree'], 253, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.016551383399209488, 0.7799157364374749, 0.18594266012231656, 2, 0.3396009305549768, 24, 8, 0.9604743083003953, 0.8102766798418972, 0.9446640316205533])\n",
      "Nominal file 1012.arff\n",
      "dict_values([['naive_bayes'], 194, 29, 2, 27, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005154639175257732, 0.9432989690721649, 0.08616029508022038, 2, 0.6508861694757068, 35, 17, 0.8402061855670103, 1.0, 0.9484536082474226])\n",
      "Numeric file 532.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 498.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 861.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1045.arff\n",
      "dict_values([['decision_tree'], 145, 94, 94, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9148936170212766, 0.0, 0.6872413793103447, 0.1402618220861321, 2, 0.2134722308902861, 8, 4, 1.0, 0.896551724137931, 0.9862068965517241])\n",
      "Nominal file 973.arff\n",
      "dict_values([['SVM_poly'], 178, 13, 13, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.31548385664164863, 0.5382443069158204, 0.40849133605541776, 2, 0.6725534572732237, 10, 5, 0.9887640449438202, 0.9719101123595506, 1.0])\n",
      "Nominal file 836.arff\n",
      "dict_values([['SVM_poly'], 34, 8, 5, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08823529411764706, 0.7941176470588235, 0.4165570675428721, 2, 0.6862107122427636, 13, 8, 0.7647058823529412, 0.6176470588235294, 0.7941176470588235])\n",
      "Nominal file 1100.arff\n",
      "dict_values([['SVM_poly'], 478, 10, 6, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.043933054393305436, 0.9246861924686193, 0.30854834960483507, 4, 1.1818116245780672, 16, 6, 0.9686192468619247, 0.6527196652719666, 0.9916317991631799])\n",
      "Numeric file 565.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 709.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 965.arff\n",
      "dict_values([['decision_tree'], 101, 17, 1, 16, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009900990099009901, 0.9207920792079208, 0.12484883984581666, 2, 0.6753469676511341, 2, 1, 1.0, 1.0, 1.0])\n",
      "Numeric file 436.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1546.arff\n",
      "dict_values([['decision_tree'], 1112, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.21310187851773307, 0.5200760524037796, 0.40227473028665756, 5, 0.4168183730486661, 130, 13, 0.9127697841726619, 0.8983812949640287, 0.908273381294964])\n",
      "Nominal file 820.arff\n",
      "dict_values([['decision_tree'], 235, 12, 12, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2043525644249954, 0.5, 0.26674281543731976, 2, 0.671248513962747, 21, 9, 0.9404255319148935, 0.8765957446808512, 0.9191489361702128])\n",
      "Nominal file 1454.arff\n",
      "dict_values([['decision_tree'], 1458, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.011727560897528449, 0.7153704396502768, 0.09798942158607647, 2, 0.3710588214839124, 97, 19, 0.908093278463649, 0.8792866941015091, 0.9032921810699589])\n",
      "Nominal file 461.arff\n",
      "dict_values([['decision_tree'], 100, 6, 3, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01, 0.95, 0.28189612342148734, 2, 0.583258840128597, 4, 3, 1.0, 0.83, 0.81])\n",
      "Nominal file 932.arff\n",
      "dict_values([['SVM_poly'], 100, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.28671168781351625, 0.5677212647970847, 0.4845115579315867, 2, 0.6859298002523728, 14, 5, 0.98, 0.8399999999999999, 1.0])\n",
      "Numeric file 898.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 877.arff\n",
      "dict_values([['SVM_poly'], 250, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4041012866556134, 0.5326339405372238, 0.4987333990321447, 2, 0.6885320764504561, 23, 8, 0.94, 0.776, 1.0])\n",
      "Nominal file 174.arff\n",
      "dict_values([['SVM_poly'], 1066, 12, 0, 12, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9777777777777777, 0.0, 0.974671669793621, 0.24444444444444444, 3, 0.032177693361891496, 14, 7, 0.9971857410881801, 0.9540337711069419, 0.99812382739212])\n",
      "Numeric file 524.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1511.arff\n",
      "dict_values([['decision_tree'], 440, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0317453161148405, 0.6772727272727272, 0.17789426720815554, 3, 0.7816736036019191, 113, 16, 0.7295454545454545, 0.4590909090909091, 0.7227272727272727])\n",
      "Nominal file 748.arff\n",
      "dict_values([['decision_tree'], 163, 5, 3, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08968929348901643, 0.6441717791411042, 0.4204397579587923, 2, 0.6006618606306209, 43, 13, 0.8650306748466259, 0.6993865030674846, 0.7791411042944786])\n",
      "Nominal file 1090.arff\n",
      "dict_values([['naive_bayes'], 53, 11, 11, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.018867924528301886, 0.5437392795883361, 0.06855690079176335, 2, 0.48430217949997767, 6, 5, 0.9811320754716981, 1.0, 0.9245283018867925])\n",
      "Nominal file 949.arff\n",
      "dict_values([['decision_tree'], 559, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009022844426692331, 0.5, 0.040075398699324694, 2, 0.41057395091227467, 96, 18, 0.8872987477638641, 0.46869409660107336, 0.8801431127012522])\n",
      "Nominal file 733.arff\n",
      "dict_values([['decision_tree'], 209, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08780000191771106, 0.18349839073523264, 0.11498113953587234, 2, 0.5812017320882035, 15, 7, 0.9808612440191388, 0.9425837320574163, 0.9521531100478469])\n",
      "Numeric file 699.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 676.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 226.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 508.arff\n",
      "dict_values([['naive_bayes'], 26, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22005185825410553, 0.4506467542459998, 0.39583850847921204, 26, 3.2580965380214826, 26, 25, 0.19230769230769232, 1.0, 1.0])\n",
      "Numeric file 1028.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 334.arff\n",
      "dict_values([['SVM_poly'], 601, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24126455906821964, 0.6572379367720466, 0.35294117647058815, 2, 0.6931457962884989, 113, 11, 0.6505823627287853, 0.5207986688851913, 0.8119800332778702])\n",
      "Nominal file 764.arff\n",
      "dict_values([['decision_tree'], 450, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.49999999999999845, 0.2272727272727271, 2, 0.3713293553783009, 55, 17, 0.9444444444444444, 0.5177777777777778, 0.9377777777777777])\n",
      "Numeric file 621.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 908.arff\n",
      "dict_values([['decision_tree'], 400, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.44066223067173593, 0.6039969428944559, 0.5006801924569648, 2, 0.6923469670899615, 95, 13, 0.6725, 0.555, 0.64])\n",
      "Nominal file 772.arff\n",
      "dict_values([['decision_tree'], 2178, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.11335360254428978, 0.6525025967072555, 0.4268654081510934, 2, 0.6870636031644224, 741, 33, 0.5780532598714417, 0.5606060606060606, 0.559228650137741])\n",
      "Numeric file 549.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 41.arff\n",
      "dict_values([['SVM_poly'], 214, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05557039014982938, 0.5978914722228003, 0.3066213794472581, 6, 1.5086584002236942, 50, 12, 0.766355140186916, 0.5514018691588785, 0.794392523364486])\n",
      "Numeric file 230.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 660.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 617.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 181.arff\n",
      "dict_values([['SVM_poly'], 1484, 8, 8, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009036144578313253, 0.6847745818410035, 0.30891372802322614, 10, 1.7262259629714785, 514, 24, 0.5943396226415094, 0.14150943396226415, 0.6246630727762803])\n",
      "Nominal file 928.arff\n",
      "dict_values([['decision_tree'], 46, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.34210526315789475, 0.5652173913043478, 0.4662471395881007, 2, 0.6893616831435102, 5, 3, 1.0, 0.9130434782608695, 0.9782608695652174])\n",
      "Nominal file 882.arff\n",
      "dict_values([['decision_tree'], 60, 15, 15, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05695517774343121, 0.5979797979797976, 0.39821034202962896, 2, 0.6925915220779792, 10, 5, 0.9833333333333333, 0.7833333333333333, 0.9500000000000001])\n",
      "Numeric file 494.arff\n",
      "The number of classes has to be greater than one; got 1 class\n",
      "Numeric file 210.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 640.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 705.arff\n",
      "dict_values([['naive_bayes'], 50, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02, 0.52, 0.048961093644733895, 30, 3.2879195222566278, 44, 12, 0.36, 1.0, 0.94])\n",
      "Nominal file 1419.arff\n",
      "dict_values([['decision_tree'], 24, 4, 0, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.4444444444444444, 3, 0.9191738293819783, 7, 4, 1.0, 0.875, 1.0])\n",
      "Nominal file 1049.arff\n",
      "dict_values([['decision_tree'], 1458, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.011727560897528449, 0.7153704396502768, 0.09798942158607647, 2, 0.3710588214839124, 97, 19, 0.908093278463649, 0.8792866941015091, 0.9032921810699589])\n",
      "Numeric file 569.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 61.arff\n",
      "dict_values([['decision_tree'], 150, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4287037037037038, 0.4675706214689266, 0.44830469240426873, 3, 1.0986122886681096, 9, 5, 0.9933333333333333, 0.96, 0.98])\n",
      "Numeric file 990.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 656.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 206.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 713.arff\n",
      "dict_values([['decision_tree'], 52, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4098557692307692, 0.6220735785953178, 0.510643115942029, 2, 0.6901856760188042, 9, 6, 0.9423076923076923, 0.8269230769230769, 0.8461538461538461])\n",
      "Nominal file 343.arff\n",
      "dict_values([['SVM_poly'], 63, 31, 27, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.04490874959734302, 0.5714285714285714, 0.2733715162735697, 4, 0.9099903298016591, 11, 5, 0.9206349206349206, 0.7619047619047619, 1.0])\n",
      "Nominal file 969.arff\n",
      "dict_values([['decision_tree'], 150, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4287037037037038, 0.4675706214689266, 0.44830469240426873, 2, 0.6365141682948128, 2, 1, 1.0, 1.0, 1.0])\n",
      "Nominal file 986.arff\n",
      "dict_values([['SVM_poly'], 364, 32, 0, 32, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0027472527472527475, 0.5934065934065934, 0.17679558011049723, 2, 0.6237665984568341, 83, 11, 0.771978021978022, 0.38461538461538464, 0.9972527472527473])\n",
      "Numeric file 601.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 744.arff\n",
      "dict_values([['decision_tree'], 250, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.27040347741091136, 0.5237864171298917, 0.43455130886822346, 2, 0.6849326630370529, 27, 7, 0.948, 0.736, 0.724])\n",
      "Nominal file 894.arff\n",
      "dict_values([['decision_tree'], 66, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19021931376016982, 0.8652475085139842, 0.5741456017143521, 2, 0.6931471805599453, 5, 3, 1.0, 0.9696969696969697, 0.9696969696969697])\n",
      "Nominal file 1008.arff\n",
      "dict_values([['naive_bayes'], 379, 8, 0, 8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.002638522427440633, 0.8390501319261213, 0.01965601965601967, 2, 0.6833372109101785, 119, 26, 0.6754617414248021, 1.0, 0.8891820580474934])\n",
      "Nominal file 528.arff\n",
      "dict_values([['naive_bayes'], 130, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.007692307692307693, 0.5987937062937063, 0.015899952320406842, 130, 4.867534450455582, 130, 129, 0.038461538461538464, 1.0, 1.0])\n",
      "Nominal file 482.arff\n",
      "dict_values([['decision_tree'], 559, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009040170218762699, 0.5, 0.04007577534697839, 14, 0.6001239614112265, 120, 24, 0.8658318425760286, 0.4150268336314848, 0.8640429338103757])\n",
      "Numeric file 695.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 553.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 800.arff\n",
      "dict_values([['decision_tree'], 74, 27, 27, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9629629629629629, 0.0, 0.41915540540540486, 0.1842561311311311, 2, 0.6799406565303493, 11, 5, 0.972972972972973, 0.5945945945945946, 0.9459459459459459])\n",
      "Nominal file 945.arff\n",
      "dict_values([['decision_tree'], 76, 6, 3, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473684, 0.7631578947368421, 0.3862777610435952, 2, 0.6917614988524178, 16, 7, 0.8947368421052632, 0.7631578947368421, 0.8421052631578947])\n",
      "Numeric file 1073.arff\n",
      "Error while parsing header, error was: Error parsing line  @relation jEdit:Metrics/4-0-final/:BugCount/4-0-final_4-2-final/\n",
      "\n",
      "Nominal file 768.arff\n",
      "dict_values([['SVM_poly'], 100, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.30648848808917495, 0.5693005538556878, 0.4765765122072223, 2, 0.6881388137135884, 16, 6, 0.9500000000000001, 0.72, 1.0])\n",
      "Nominal file 338.arff\n",
      "dict_values([['SVM_poly'], 155, 8, 2, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01935483870967742, 0.7935483870967742, 0.14412186379928318, 4, 1.333634831855001, 80, 17, 0.5548387096774193, 0.5161290322580645, 0.8322580645161292])\n",
      "Nominal file 787.arff\n",
      "dict_values([['naive_bayes'], 50, 5, 4, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02, 0.5595833333333332, 0.05454574835968034, 2, 0.6923469670899615, 11, 6, 0.96, 1.0, 1.0])\n",
      "Nominal file 857.arff\n",
      "dict_values([['decision_tree'], 40, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2486891673714154, 0.7000000000000003, 0.49266988105305937, 2, 0.6474466390346325, 7, 5, 0.975, 0.9500000000000001, 0.975])\n",
      "Numeric file 504.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1531.arff\n",
      "dict_values([['decision_tree'], 10176, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5026674678877573, 0.5111807386711884, 0.5061041923947747, 5, 0.2043403301418198, 520, 29, 0.968062106918239, 0.9608883647798742, 0.964622641509434])\n",
      "Numeric file 441.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 912.arff\n",
      "dict_values([['decision_tree'], 1000, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3744385364530236, 0.5148004597452116, 0.47871227013868206, 2, 0.678968036741767, 76, 11, 0.914, 0.832, 0.761])\n",
      "Nominal file 791.arff\n",
      "dict_values([['decision_tree'], 43, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.553235247587407, 0.7239987080103358, 0.6386169777988715, 2, 0.6710806543560228, 15, 8, 0.9069767441860465, 0.6976744186046512, 0.7209302325581395])\n",
      "Nominal file 1527.arff\n",
      "dict_values([['decision_tree'], 3252, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19953389725658308, 0.4958972697698713, 0.3945718803976974, 5, 0.4342902769524296, 149, 15, 0.9261992619926199, 0.9114391143911439, 0.9182041820418204])\n",
      "Numeric file 512.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 841.arff\n",
      "dict_values([['SVM_poly'], 950, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4263260091977515, 0.602573812580231, 0.5013207067815534, 2, 0.6927726185565874, 40, 11, 0.9484210526315789, 0.7063157894736842, 0.9642105263157895])\n",
      "Nominal file 457.arff\n",
      "dict_values([['decision_tree'], 27, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.037037037037037035, 0.18886983037926436, 0.04667988821489559, 4, 1.2374256801772396, 7, 3, 1.0, 1.0, 1.0])\n",
      "Nominal file 1462.arff\n",
      "dict_values([['SVM_poly'], 1372, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2879241439945749, 0.66891654426498, 0.520813932237652, 2, 0.6869976659350199, 27, 7, 0.9620991253644315, 0.8411078717201167, 1.0])\n",
      "Nominal file 729.arff\n",
      "dict_values([['decision_tree'], 44, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.38313858203065754, 0.5498165333121903, 0.4776517051142826, 2, 0.6670936741211575, 6, 4, 1.0, 0.9318181818181818, 1.0])\n",
      "Numeric file 683.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 545.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1065.arff\n",
      "dict_values([['decision_tree'], 458, 39, 39, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.012372634643376998, 0.9010623737209148, 0.15788842615941082, 2, 0.3114386363618641, 36, 13, 0.9519650655021834, 0.8471615720524016, 0.9192139737991266])\n",
      "Numeric file 1435.arff\n",
      "could not convert string to float: '{0 0.747253'\n",
      "Nominal file 775.arff\n",
      "dict_values([['SVM_poly'], 100, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4084442707134632, 0.5572675119628893, 0.49783339367480556, 2, 0.683314913574166, 13, 6, 0.97, 0.85, 1.0])\n",
      "Numeric file 630.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 519.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 11.arff\n",
      "dict_values([['SVM_poly'], 625, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 3, 0.9136485598712407, 161, 10, 0.8272, 0.9088, 0.9792])\n",
      "Nominal file 333.arff\n",
      "dict_values([['SVM_poly'], 556, 6, 0, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24640287769784172, 0.5053956834532374, 0.3529411764705882, 2, 0.6929142552752339, 216, 11, 0.5431654676258992, 0.5269784172661871, 0.5665467625899281])\n",
      "Nominal file 763.arff\n",
      "dict_values([['SVM_poly'], 250, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.47252030294164815, 0.5360536255350847, 0.5066303279983907, 2, 0.6931471805599453, 37, 10, 0.928, 0.8599999999999999, 0.964])\n",
      "Nominal file 276.arff\n",
      "dict_values([['decision_tree'], 74, 62, 62, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.9053955021061313, 0.3235705529311787, 4, 0.908043522184999, 19, 8, 0.9459459459459459, 0.4189189189189189, 0.8513513513513514])\n",
      "Nominal file 1490.arff\n",
      "dict_values([['SVM_poly'], 182, 12, 12, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.47107811748261735, 0.6673404264950106, 0.5476060429110094, 2, 0.5982695885852573, 38, 12, 0.7527472527472527, 0.7087912087912089, 0.7857142857142857])\n",
      "Nominal file 919.arff\n",
      "dict_values([['decision_tree'], 40, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5275531914893619, 0.5137765957446809, 2, 0.6918966592050799, 2, 1, 1.0, 0.925, 1.0])\n",
      "Numeric file 671.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1097.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 50.arff\n",
      "dict_values([['SVM_poly'], 958, 9, 0, 9, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16701461377870563, 0.4780793319415449, 0.33333333333333326, 2, 0.6452881308007814, 73, 12, 0.8434237995824636, 0.673277661795407, 0.9916492693110647])\n",
      "Nominal file 935.arff\n",
      "dict_values([['decision_tree'], 250, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4530121444103195, 0.5427714984168278, 0.49780952184097965, 2, 0.6859298002523728, 23, 7, 0.972, 0.7160000000000001, 0.848])\n",
      "Nominal file 1003.arff\n",
      "dict_values([['SVM_poly'], 339, 17, 0, 17, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0029498525073746312, 0.9793510324483776, 0.40476190476190477, 2, 0.5598915082116096, 69, 14, 0.8967551622418879, 0.8141592920353983, 0.9557522123893806])\n",
      "Numeric file 466.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1453.arff\n",
      "dict_values([['decision_tree'], 1077, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0037304104189780094, 0.5980899323517703, 0.08881168895724173, 2, 0.3756393775122172, 102, 15, 0.8960074280408542, 0.31940575673166205, 0.8820798514391829])\n",
      "Nominal file 173.arff\n",
      "dict_values([['decision_tree'], 323, 12, 0, 12, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.006191950464396285, 0.9721362229102167, 0.31578947368421045, 2, 0.10447612961011349, 19, 6, 0.9845201238390093, 0.7213622291021671, 0.9814241486068112])\n",
      "Nominal file 1516.arff\n",
      "dict_values([['naive_bayes'], 88, 90, 90, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.288404452690167, 0.8748998459167954, 0.5406083448594827, 4, 1.336913230001689, 12, 6, 0.9545454545454546, 0.9659090909090909, 0.9318181818181818])\n",
      "Nominal file 523.arff\n",
      "dict_values([['naive_bayes'], 100, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01, 0.54, 0.024336569579288037, 3, 0.28234708920188, 8, 7, 0.97, 1.0, 0.94])\n",
      "Nominal file 870.arff\n",
      "dict_values([['decision_tree'], 500, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4888158530564234, 0.5189693338501268, 0.5014635929758363, 2, 0.690833395474842, 55, 9, 0.914, 0.724, 0.698])\n",
      "Numeric file 431.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1054.arff\n",
      "dict_values([['decision_tree'], 161, 39, 39, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05515036873811638, 0.7740993788819875, 0.17616065283353538, 2, 0.6290963368527184, 28, 10, 0.8260869565217391, 0.7391304347826085, 0.8012422360248448])\n",
      "Nominal file 962.arff\n",
      "dict_values([['SVM_poly'], 2000, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.14269999999999883, 0.4318956385465354, 0.2921223977809136, 2, 0.3250829733914482, 14, 7, 0.996, 0.9985, 0.999])\n",
      "Nominal file 827.arff\n",
      "dict_values([['decision_tree'], 662, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4137974984065563, 0.511911396806517, 0.45763450652228904, 2, 0.6931289257779522, 213, 25, 0.5996978851963746, 0.5347432024169184, 0.5453172205438066])\n",
      "Nominal file 1541.arff\n",
      "dict_values([['decision_tree'], 8654, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49405085845068925, 0.5071924403868863, 0.4986841202183235, 5, 0.28834719445974993, 753, 30, 0.9445343193898775, 0.9341345042754795, 0.9432632308758956])\n",
      "Nominal file 1.arff\n",
      "dict_values([['SVM_poly'], 898, 38, 6, 32, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9166666666666666, 0.0, 0.9988864142538976, 0.31261842465749123, 5, 0.8247299827628457, 15, 8, 0.9788418708240535, 0.9298440979955458, 0.9810690423162584])\n",
      "Nominal file 974.arff\n",
      "dict_values([['decision_tree'], 132, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3181818181818181, 0.5, 0.3636363636363636, 2, 0.6670936741211575, 28, 9, 0.8636363636363636, 0.6136363636363636, 0.7272727272727273])\n",
      "Numeric file 427.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 1412.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 1557.arff\n",
      "dict_values([['SVM_poly'], 4177, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12346584011474561, 0.6067460805310956, 0.33307219257165627, 3, 1.0979199138101299, 1054, 26, 0.6356236533397175, 0.5712233660521906, 0.6495092171414891])\n",
      "Numeric file 831.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 759.arff\n",
      "dict_values([['decision_tree'], 66, 12, 11, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.015151515151515152, 0.49223616546975785, 0.04353434598187354, 2, 0.6931471805599453, 2, 1, 1.0, 1.0, 0.9090909090909091])\n",
      "Nominal file 470.arff\n",
      "dict_values([['decision_tree'], 672, 9, 5, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005952380952380952, 0.8333333333333334, 0.08823425746355833, 2, 0.19144408195771734, 48, 17, 0.9553571428571429, 0.4226190476190476, 0.9553571428571429])\n",
      "Nominal file 1015.arff\n",
      "dict_values([['decision_tree'], 72, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.28782821725041063, 0.43495188727226486, 0.3795187775263809, 2, 0.45056120886630463, 10, 7, 0.9444444444444444, 0.8055555555555556, 0.9027777777777778])\n",
      "Nominal file 889.arff\n",
      "dict_values([['SVM_poly'], 100, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.45817132908260205, 0.5542406694687065, 0.505150224233927, 2, 0.6931471805599453, 14, 7, 0.91, 0.8599999999999999, 1.0])\n",
      "Nominal file 923.arff\n",
      "dict_values([['decision_tree'], 8641, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24163869922462677, 0.7583613007753732, 0.4559008611125478, 2, 0.6881283578454834, 5, 3, 1.0, 0.6915866219187594, 0.999884272653628])\n",
      "Nominal file 535.arff\n",
      "dict_values([['naive_bayes'], 100, 3, 1, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1, 0.5, 0.17647058823529416, 86, 4.411088975431305, 89, 13, 0.22, 1.0, 1.0])\n",
      "Nominal file 1500.arff\n",
      "dict_values([['SVM_poly'], 210, 7, 7, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3816329626416873, 0.5707674358309562, 0.4421524746317417, 3, 1.0986122886681096, 16, 6, 0.9571428571428572, 0.9095238095238095, 0.9714285714285714])\n",
      "Numeric file 542.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 811.arff\n",
      "dict_values([['SVM_poly'], 264, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.49999999999999933, 0.11538461538461532, 2, 0.6653110162809015, 25, 11, 0.9166666666666666, 0.6325757575757576, 0.946969696969697])\n",
      "Nominal file 1062.arff\n",
      "dict_values([['decision_tree'], 36, 29, 29, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09956304619225968, 0.3685897435897437, 0.1820500933109957, 2, 0.5297061990576545, 5, 3, 1.0, 0.8611111111111112, 0.9444444444444444])\n",
      "Numeric file 684.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 515.arff\n",
      "dict_values([['naive_bayes'], 26, 8, 5, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.038461538461538464, 0.61013986013986, 0.14822715227318584, 26, 3.2580965380214826, 26, 13, 0.19230769230769232, 1.0, 1.0])\n",
      "Nominal file 1520.arff\n",
      "dict_values([['decision_tree'], 164, 90, 90, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1563003500194454, 0.9512746170214567, 0.5972959137211034, 5, 1.558297694030996, 27, 6, 0.9024390243902439, 0.7073170731707317, 0.823170731707317])\n",
      "Nominal file 1465.arff\n",
      "dict_values([['SVM_poly'], 106, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.47902448815736653, 0.5038098693759071, 0.49676035683748015, 6, 1.7776506790631137, 43, 10, 0.6415094339622641, 0.6320754716981132, 0.9339622641509434])\n",
      "Nominal file 450.arff\n",
      "dict_values([['decision_tree'], 264, 4, 3, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2828369596438317, 0.660158175734499, 0.4980967824067548, 2, 0.2587043978901781, 8, 5, 0.9962121212121212, 0.9507575757575758, 0.9848484848484849])\n",
      "Numeric file 1035.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 329.arff\n",
      "dict_values([['naive_bayes'], 160, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.32499999999999996, 0.4125, 0.346875, 3, 1.0504407326258585, 25, 10, 0.71875, 0.8000000000000002, 0.79375])\n",
      "Nominal file 779.arff\n",
      "dict_values([['SVM_poly'], 500, 25, 25, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4677568397752018, 0.5294851110792319, 0.4973775537532406, 2, 0.690833395474842, 46, 11, 0.91, 0.688, 0.986])\n",
      "Nominal file 796.arff\n",
      "dict_values([['decision_tree'], 209, 7, 6, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.004784688995215311, 0.18349839073523264, 0.046941301033756495, 2, 0.5662433019686854, 10, 5, 0.9952153110047847, 0.6363636363636364, 0.9234449760765551])\n",
      "Nominal file 1536.arff\n",
      "dict_values([['decision_tree'], 10130, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5027996927045207, 0.5082145836535704, 0.5052073057826013, 5, 0.20461023381301652, 531, 28, 0.9679170779861797, 0.9608094768015795, 0.9645607107601185])\n",
      "Nominal file 850.arff\n",
      "dict_values([['SVM_poly'], 100, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.45266703705996114, 0.5460982596472873, 0.5005228747766085, 2, 0.6929471672244782, 17, 7, 0.94, 0.9, 1.0])\n",
      "Nominal file 915.arff\n",
      "dict_values([['decision_tree'], 315, 13, 10, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.01615450778012355, 0.8666666666666667, 0.2931257744955405, 2, 0.6809991432654108, 75, 13, 0.7047619047619048, 0.5301587301587302, 0.6888888888888889])\n",
      "Nominal file 1023.arff\n",
      "dict_values([['SVM_poly'], 683, 35, 0, 35, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0014641288433382138, 0.9355783308931186, 0.26315789473684204, 2, 0.3952242660488051, 26, 10, 0.9633967789165446, 0.8667642752562226, 0.9926793557833089])\n",
      "Numeric file 446.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 1473.arff\n",
      "dict_values([['SVM_poly'], 100, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.325, 0.87, 0.5219429078014185, 2, 0.3669249912727096, 22, 7, 0.92, 0.87, 0.96])\n",
      "Nominal file 780.arff\n",
      "dict_values([['decision_tree'], 51, 6, 6, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.13811222655493793, 0.6732026143790846, 0.4720766460143257, 2, 0.6774944044487072, 12, 6, 0.9215686274509803, 0.7843137254901961, 0.8627450980392157])\n",
      "Numeric file 411.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1074.arff\n",
      "dict_values([['decision_tree'], 81, 11, 11, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.19237020783001227, 0.6370370370370368, 0.37204629808239614, 3, 0.9424090214607863, 19, 7, 0.9382716049382716, 0.7777777777777778, 0.9259259259259259])\n",
      "Nominal file 942.arff\n",
      "dict_values([['naive_bayes'], 50, 4, 2, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02, 0.52, 0.048961093644733895, 2, 0.6923469670899615, 19, 14, 0.76, 1.0, 1.0])\n",
      "Numeric file 692.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 738.arff\n",
      "dict_values([['naive_bayes'], 195, 11, 1, 10, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.005128205128205128, 0.764102564102564, 0.04852135631952143, 2, 0.66381251797752, 32, 15, 0.8769230769230769, 0.9641025641025641, 0.9230769230769231])\n",
      "Numeric file 190.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 893.arff\n",
      "dict_values([['decision_tree'], 73, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2783401329784502, 0.4522356552625908, 0.3806765475372581, 2, 0.6885426234367296, 14, 7, 0.9041095890410958, 0.6164383561643836, 0.726027397260274])\n",
      "Numeric file 939.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 27.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 485.arff\n",
      "dict_values([['naive_bayes'], 48, 4, 1, 3, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.5, 0.33333333333333326, 47, 3.8423198783845605, 47, 8, 0.3541666666666667, 1.0, 1.0])\n",
      "Numeric file 606.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 743.arff\n",
      "dict_values([['decision_tree'], 1000, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.49018641041352007, 0.5038760481323065, 0.4986769626947566, 2, 0.6894446086193584, 88, 13, 0.88, 0.663, 0.695])\n",
      "Numeric file 1058.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 597.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 578.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 651.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 714.arff\n",
      "dict_values([['decision_tree'], 125, 4, 2, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.6031999999999997, 0.38935061728395054, 2, 0.6696343095488462, 55, 16, 0.704, 0.592, 0.64])\n",
      "Numeric file 581.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 997.arff\n",
      "dict_values([['SVM_poly'], 625, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 2, 0.6900707444437642, 120, 11, 0.88, 0.9552, 0.9792])\n",
      "Numeric file 217.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 647.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 702.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 885.arff\n",
      "dict_values([['decision_tree'], 131, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1323155216284987, 0.5, 0.2748792679803355, 2, 0.6570185524324769, 2, 1, 1.0, 0.9694656488549618, 1.0])\n",
      "Numeric file 186.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1449.arff\n",
      "dict_values([['decision_tree'], 253, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.016551383399209488, 0.7799157364374749, 0.18594266012231656, 2, 0.3396009305549768, 24, 8, 0.9604743083003953, 0.8102766798418972, 0.9446640316205533])\n",
      "Numeric file 493.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 539.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 31.arff\n",
      "dict_values([['SVM_poly'], 1000, 20, 7, 13, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009, 0.963, 0.250387079048344, 2, 0.6108643020548935, 188, 16, 0.7579999999999999, 0.726, 0.9209999999999999])\n",
      "Nominal file 755.arff\n",
      "dict_values([['decision_tree'], 62, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4332591768631812, 0.5676890534108938, 0.5003224733792933, 2, 0.6931471805599453, 12, 7, 0.9516129032258065, 0.7903225806451614, 0.8870967741935484])\n",
      "Numeric file 611.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 754.arff\n",
      "dict_values([['SVM_poly'], 100, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4334066311094478, 0.5335494719343334, 0.49185077047988857, 2, 0.6899437584583995, 17, 9, 0.93, 0.91, 0.9500000000000001])\n",
      "Nominal file 884.arff\n",
      "dict_values([['SVM_poly'], 500, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.465102772648859, 0.5159500844563722, 0.4935999106811641, 2, 0.6931391805386118, 66, 11, 0.864, 0.842, 0.894])\n",
      "Nominal file 1448.arff\n",
      "dict_values([['decision_tree'], 194, 39, 39, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02577319587628865, 0.8261270964763815, 0.19311907620566068, 2, 0.4797308549257987, 33, 15, 0.9175257731958762, 0.7938144329896907, 0.8608247422680413])\n",
      "Nominal file 187.arff\n",
      "dict_values([['SVM_poly'], 178, 13, 13, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2696629213483146, 0.5382443069158204, 0.39839609284446414, 121, 4.662864049996065, 150, 20, 0.14606741573033707, 0.842696629213483, 0.893258426966292])\n",
      "Nominal file 492.arff\n",
      "dict_values([['naive_bayes'], 140, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02857142857142857, 0.4160714285714286, 0.12290101984346588, 62, 3.76452737625794, 121, 26, 0.22857142857142856, 0.5142857142857142, 0.2642857142857143])\n",
      "Numeric file 646.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 703.arff\n",
      "dict_values([['SVM_poly'], 526, 5, 4, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0019011406844106464, 0.6634980988593155, 0.010720974664006315, 3, 1.098369090666213, 309, 83, 0.3897338403041825, 0.6349809885931559, 0.7737642585551332])\n",
      "Nominal file 996.arff\n",
      "dict_values([['decision_tree'], 214, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05557039014982941, 0.5978914722228007, 0.30662137944725815, 2, 0.6505706766412187, 33, 10, 0.8644859813084113, 0.602803738317757, 0.808411214953271])\n",
      "Numeric file 200.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 345.arff\n",
      "dict_values([['decision_tree'], 76, 45, 0, 45, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013157894736842105, 0.9868421052631579, 0.18595041322314057, 3, 0.33091306824075495, 5, 4, 1.0, 1.0, 0.9868421052631579])\n",
      "Numeric file 596.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1059.arff\n",
      "dict_values([['decision_tree'], 121, 29, 29, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02295684113865932, 0.47564621065588175, 0.18165073937449389, 2, 0.2648244730258604, 14, 7, 0.9752066115702479, 0.7520661157024794, 0.9338842975206612])\n",
      "Numeric file 579.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 191.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 892.arff\n",
      "dict_values([['decision_tree'], 50, 7, 6, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02, 0.6973946360153258, 0.06943633518514523, 2, 0.6923469670899615, 4, 3, 1.0, 1.0, 1.0])\n",
      "Nominal file 938.arff\n",
      "dict_values([['decision_tree'], 42, 10, 8, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.023809523809523808, 0.3298412698412698, 0.04746946611013171, 2, 0.6886051523183013, 6, 3, 1.0, 1.0, 1.0])\n",
      "Numeric file 693.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 739.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 555.arff\n",
      "dict_values([['SVM_poly'], 450, 3, 2, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.49999999999999845, 0.2272727272727271, 159, 3.0095284824568687, 285, 23, 0.5355555555555556, 0.3511111111111111, 0.6222222222222222])\n",
      "Nominal file 1075.arff\n",
      "dict_values([['decision_tree'], 130, 8, 8, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.15731575568742276, 0.46153846153846156, 0.24064465086613354, 2, 0.28989949906285883, 14, 9, 0.9615384615384616, 0.8461538461538461, 0.9384615384615385])\n",
      "Nominal file 943.arff\n",
      "dict_values([['SVM_poly'], 500, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4877475438211174, 0.5137286161639365, 0.5021357672772008, 2, 0.6924990405193354, 59, 11, 0.892, 0.868, 0.948])\n",
      "Nominal file 1167.arff\n",
      "dict_values([['decision_tree'], 320, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.003125, 0.9875, 0.20299715909090912, 2, 0.6372337564702363, 66, 13, 0.7281249999999999, 0.68125, 0.696875])\n",
      "Numeric file 502.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 914.arff\n",
      "dict_values([['SVM_poly'], 2001, 2, 2, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.8515742128935343, 0.6757871064467671, 2, 0.5520916602132345, 33, 9, 0.9650174912543729, 0.8435782108945528, 0.9735132433783108])\n",
      "Nominal file 1472.arff\n",
      "dict_values([['SVM_poly'], 768, 9, 8, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0013020833333333333, 0.6018518518518486, 0.11364546590241026, 38, 3.2603612288520973, 370, 23, 0.48046875, 0.45572916666666663, 0.66015625])\n",
      "Nominal file 328.arff\n",
      "dict_values([['naive_bayes'], 105, 12, 0, 12, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009523809523809525, 0.8285714285714286, 0.06060606060606057, 6, 1.6064398546647178, 31, 14, 0.7142857142857143, 1.0, 0.9619047619047619])\n",
      "Nominal file 778.arff\n",
      "dict_values([['decision_tree'], 252, 14, 14, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.23771550087339557, 0.8424623735504573, 0.395680483413358, 2, 0.6930211989529488, 2, 1, 1.0, 0.8015873015873016, 0.996031746031746])\n",
      "Nominal file 1464.arff\n",
      "dict_values([['decision_tree'], 748, 4, 4, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09213685474189705, 0.33627172459893073, 0.16225353585844682, 2, 0.5487262431826446, 199, 19, 0.7994652406417111, 0.75, 0.7673796791443851])\n",
      "Numeric file 451.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 902.arff\n",
      "dict_values([['decision_tree'], 147, 6, 2, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24489795918367346, 0.7551020408163265, 0.5222539682539683, 2, 0.6912717888263618, 57, 11, 0.782312925170068, 0.6462585034013606, 0.7142857142857143])\n",
      "Nominal file 685.arff\n",
      "dict_values([['naive_bayes'], 130, 2, 1, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.038461538461538464, 0.2, 0.06451612903225813, 129, 4.856870647677737, 129, 29, 0.09230769230769231, 1.0, 1.0])\n",
      "Numeric file 543.arff\n",
      "Error while parsing header, error was: 'utf-8' codec can't decode byte 0x93 in position 388: invalid start byte\n",
      "Numeric file 810.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 955.arff\n",
      "dict_values([['decision_tree'], 151, 5, 3, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.152317880794702, 0.847682119205298, 0.4579610608040125, 2, 0.6438921644337414, 43, 13, 0.8344370860927153, 0.7284768211920529, 0.76158940397351])\n",
      "Nominal file 1063.arff\n",
      "dict_values([['decision_tree'], 522, 21, 21, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.007153432503769244, 0.17821089455272343, 0.041712471251169926, 2, 0.5072302867654668, 71, 15, 0.8850574712643678, 0.8371647509578544, 0.8582375478927203])\n",
      "Numeric file 406.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1444.arff\n",
      "dict_values([['decision_tree'], 1043, 37, 37, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0032900662593441203, 0.5953587571174199, 0.09033326786481621, 2, 0.37042524692623313, 106, 15, 0.9079578139980825, 0.311601150527325, 0.8849472674976031])\n",
      "Numeric file 471.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1014.arff\n",
      "dict_values([['decision_tree'], 797, 4, 0, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.027603513174404015, 0.5119196988707654, 0.19047619047619047, 2, 0.4926531931045961, 178, 17, 0.8067754077791719, 0.617314930991217, 0.8055207026348808])\n",
      "Nominal file 922.arff\n",
      "dict_values([['SVM_poly'], 100, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3507708251366541, 0.5524014551163499, 0.49861215700652806, 2, 0.6802920001921535, 9, 5, 0.99, 0.88, 1.0])\n",
      "Nominal file 867.arff\n",
      "dict_values([['SVM_poly'], 130, 2, 0, 2, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.038461538461538464, 0.2, 0.06451612903225813, 2, 0.4895518936229288, 23, 10, 0.9230769230769231, 0.6692307692307692, 1.0])\n",
      "Nominal file 534.arff\n",
      "dict_values([['decision_tree'], 534, 10, 4, 6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0449438202247191, 0.8239700374531835, 0.3457540940815073, 2, 0.6440198399540822, 153, 20, 0.7453183520599251, 0.6385767790262172, 0.7340823970037453])\n",
      "Nominal file 164.arff\n",
      "dict_values([['naive_bayes'], 106, 58, 0, 58, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009433962264150943, 0.5094339622641509, 0.1746987951807228, 4, 1.3582484681410505, 36, 9, 0.6792452830188679, 1.0, 1.0])\n",
      "Nominal file 758.arff\n",
      "dict_values([['decision_tree'], 67, 15, 14, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.014925373134328358, 0.1786518659033543, 0.030321089175692352, 2, 0.5819181977558665, 3, 2, 1.0, 1.0, 0.9104477611940298])\n",
      "Numeric file 975.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 426.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 1556.arff\n",
      "dict_values([['decision_tree'], 120, 6, 1, 5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.24166666666666667, 0.7583333333333333, 0.5033964646464647, 2, 0.6930082852403007, 4, 3, 1.0, 0.825, 1.0])\n",
      "Numeric file 563.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 830.arff\n",
      "dict_values([['decision_tree'], 250, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.37264581778598543, 0.537730106530528, 0.49220238135887895, 2, 0.6556849848780457, 25, 9, 0.948, 0.844, 0.9])\n",
      "Nominal file 1055.arff\n",
      "dict_values([['SVM_poly'], 89, 8, 7, 1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.02247191011235955, 0.449438202247191, 0.18792134831460677, 2, 0.5328162091895474, 18, 9, 0.8314606741573034, 0.7752808988764045, 0.842696629213483])\n",
      "Numeric file 963.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 826.arff\n",
      "dict_values([['SVM_poly'], 576, 11, 0, 11, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.5, 0.3055555555555556, 2, 0.678602909931348, 207, 14, 0.734375, 0.671875, 0.9027777777777778])\n",
      "Numeric file 575.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1540.arff\n",
      "dict_values([['decision_tree'], 9285, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4942743889728475, 0.5153116258885858, 0.5024195313939435, 5, 0.2833873945836083, 753, 28, 0.9458266020463112, 0.9363489499192246, 0.9446418955304254])\n",
      "Nominal file 719.arff\n",
      "dict_values([['decision_tree'], 137, 7, 3, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06569343065693431, 0.9343065693430657, 0.39640585609423923, 2, 0.6221611118996319, 39, 11, 0.8467153284671532, 0.7445255474452555, 0.8029197080291971])\n",
      "Nominal file 934.arff\n",
      "dict_values([['decision_tree'], 1156, 5, 1, 4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.022699643500786126, 0.5, 0.10314614470514837, 2, 0.5287411938874718, 69, 12, 0.9524221453287197, 0.9143598615916955, 0.9498269896193772])\n",
      "Numeric file 467.arff\n",
      "Unknown label type: 'continuous'\n",
      "Nominal file 1452.arff\n",
      "dict_values([['decision_tree'], 745, 36, 36, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.009603317509685178, 0.8103692470584231, 0.1059029359861772, 2, 0.10373110403036712, 23, 10, 0.9865771812080537, 0.9328859060402684, 0.9798657718120806])\n",
      "Numeric file 488.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Nominal file 1517.arff\n",
      "dict_values([['naive_bayes'], 47, 90, 90, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12727272727272732, 0.8684124386252046, 0.4977427056527134, 5, 1.4648543232412963, 10, 5, 0.9787234042553191, 1.0, 1.0])\n",
      "Numeric file 522.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 871.arff\n",
      "dict_values([['decision_tree'], 3848, 5, 5, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.48715550631347143, 0.5255852641261309, 0.5059978905081731, 2, 0.6931471805599453, 1056, 43, 0.5317047817047817, 0.5111746361746362, 0.5298856548856549])\n",
      "Numeric file 1096.arff\n",
      "Unknown label type: 'continuous'\n",
      "Numeric file 559.arff\n",
      "Input y contains NaN.\n",
      "Numeric file 51.arff\n",
      "Input X contains NaN.\n",
      "DecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Numeric file 670.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 918.arff\n",
      "dict_values([['SVM_poly'], 250, 50, 50, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.27217955931058707, 0.5306035431936944, 0.4894689109836728, 2, 0.6899437584583995, 27, 9, 0.92, 0.76, 1.0])\n",
      "Nominal file 762.arff\n",
      "dict_values([['decision_tree'], 100, 10, 10, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.37732647512416917, 0.5398246553867763, 0.47885198959752373, 2, 0.6881388137135884, 15, 6, 0.97, 0.78, 0.94])\n",
      "Nominal file 277.arff\n",
      "dict_values([['decision_tree'], 74, 62, 62, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.9053955021061313, 0.3235705529311787, 4, 1.0700156993340486, 18, 9, 0.8648648648648649, 0.6216216216216216, 0.8648648648648649])\n",
      "Numeric file 627.arff\n",
      "Can only use .str accessor with string values!\n",
      "Nominal file 518.arff\n",
      "dict_values([['naive_bayes'], 74, 9, 9, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.716652136006975, 0.040326987874669325, 4, 1.0228817688386447, 9, 5, 0.9864864864864865, 1.0, 0.9324324324324325])\n",
      "Nominal file 10.arff\n",
      "dict_values([['SVM_poly'], 148, 18, 3, 15, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.013513513513513514, 0.9527027027027027, 0.3351098058544867, 4, 0.850961199111149, 24, 7, 0.918918918918919, 0.6418918918918919, 1.0])\n",
      "Nominal file 774.arff\n",
      "dict_values([['decision_tree'], 662, 3, 3, 0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4196917267062214, 0.516237160141609, 0.4584382461543794, 2, 0.69225243479665, 211, 16, 0.6435045317220544, 0.5664652567975831, 0.5498489425981873])\n",
      "Numeric file 631.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 689.arff\n",
      "Can only use .str accessor with string values!\n",
      "Numeric file 666.arff\n",
      "Can only use .str accessor with string values!\n"
     ]
    },
    {
     "data": {
      "text/plain": "         best_algo  objects_count  features_count  numeric_count  \\\n0    decision_tree             60               7              6   \n1    decision_tree            132               3              2   \n2    decision_tree            327              37             37   \n3    decision_tree            226              69              0   \n4    decision_tree           1080               3              3   \n..             ...            ...             ...            ...   \n427  decision_tree            100              10             10   \n428  decision_tree             74              62             62   \n429    naive_bayes             74               9              9   \n430       SVM_poly            148              18              3   \n431  decision_tree            662               3              3   \n\n     nominal_count  min/min  min/max  min/mean  max/min  max/max  ...  \\\n0                1      0.0      0.0       0.0      1.0      1.0  ...   \n1                1      0.0      0.0       0.0      1.0      1.0  ...   \n2                0      0.0      0.0       0.0      1.0      1.0  ...   \n3               69      0.0      0.0       0.0      1.0      1.0  ...   \n4                0      0.0      0.0       0.0      1.0      1.0  ...   \n..             ...      ...      ...       ...      ...      ...  ...   \n427              0      0.0      0.0       0.0      1.0      1.0  ...   \n428              0      0.0      0.0       0.0      1.0      1.0  ...   \n429              0      0.0      0.0       0.0      1.0      1.0  ...   \n430             15      0.0      0.0       0.0      1.0      1.0  ...   \n431              0      0.0      0.0       0.0      1.0      1.0  ...   \n\n     mean/min  mean/max  mean/mean  uniques_count   entropy  tree_n_leaves  \\\n0    0.500000  0.655294   0.592063              2  0.688139             16   \n1    0.223868  0.500000   0.344774              2  0.646504             11   \n2    0.023268  0.688928   0.131833              2  0.383411             41   \n3    0.004425  0.995575   0.428571              2  0.564753             11   \n4    0.225631  0.530038   0.409746              5  0.404633            125   \n..        ...       ...        ...            ...       ...            ...   \n427  0.377326  0.539825   0.478852              2  0.688139             15   \n428  0.013514  0.905396   0.323571              4  1.070016             18   \n429  0.013514  0.716652   0.040327              4  1.022882              9   \n430  0.013514  0.952703   0.335110              4  0.850961             24   \n431  0.419692  0.516237   0.458438              2  0.692252            211   \n\n     tree_max_depth  decision_tree  naive_bayes  SVM_poly  \n0                10       0.850000     0.733333  0.800000  \n1                 6       0.984848     0.916667  0.977273  \n2                10       0.914373     0.822630  0.886850  \n3                 7       0.986726     0.960177  0.986726  \n4                15       0.914815     0.902778  0.911111  \n..              ...            ...          ...       ...  \n427               6       0.970000     0.780000  0.940000  \n428               9       0.864865     0.621622  0.864865  \n429               5       0.986486     1.000000  0.932432  \n430               7       0.918919     0.641892  1.000000  \n431              16       0.643505     0.566465  0.549849  \n\n[432 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best_algo</th>\n      <th>objects_count</th>\n      <th>features_count</th>\n      <th>numeric_count</th>\n      <th>nominal_count</th>\n      <th>min/min</th>\n      <th>min/max</th>\n      <th>min/mean</th>\n      <th>max/min</th>\n      <th>max/max</th>\n      <th>...</th>\n      <th>mean/min</th>\n      <th>mean/max</th>\n      <th>mean/mean</th>\n      <th>uniques_count</th>\n      <th>entropy</th>\n      <th>tree_n_leaves</th>\n      <th>tree_max_depth</th>\n      <th>decision_tree</th>\n      <th>naive_bayes</th>\n      <th>SVM_poly</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>decision_tree</td>\n      <td>60</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.500000</td>\n      <td>0.655294</td>\n      <td>0.592063</td>\n      <td>2</td>\n      <td>0.688139</td>\n      <td>16</td>\n      <td>10</td>\n      <td>0.850000</td>\n      <td>0.733333</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>decision_tree</td>\n      <td>132</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.223868</td>\n      <td>0.500000</td>\n      <td>0.344774</td>\n      <td>2</td>\n      <td>0.646504</td>\n      <td>11</td>\n      <td>6</td>\n      <td>0.984848</td>\n      <td>0.916667</td>\n      <td>0.977273</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>decision_tree</td>\n      <td>327</td>\n      <td>37</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.023268</td>\n      <td>0.688928</td>\n      <td>0.131833</td>\n      <td>2</td>\n      <td>0.383411</td>\n      <td>41</td>\n      <td>10</td>\n      <td>0.914373</td>\n      <td>0.822630</td>\n      <td>0.886850</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>decision_tree</td>\n      <td>226</td>\n      <td>69</td>\n      <td>0</td>\n      <td>69</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.004425</td>\n      <td>0.995575</td>\n      <td>0.428571</td>\n      <td>2</td>\n      <td>0.564753</td>\n      <td>11</td>\n      <td>7</td>\n      <td>0.986726</td>\n      <td>0.960177</td>\n      <td>0.986726</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>decision_tree</td>\n      <td>1080</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.225631</td>\n      <td>0.530038</td>\n      <td>0.409746</td>\n      <td>5</td>\n      <td>0.404633</td>\n      <td>125</td>\n      <td>15</td>\n      <td>0.914815</td>\n      <td>0.902778</td>\n      <td>0.911111</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>427</th>\n      <td>decision_tree</td>\n      <td>100</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.377326</td>\n      <td>0.539825</td>\n      <td>0.478852</td>\n      <td>2</td>\n      <td>0.688139</td>\n      <td>15</td>\n      <td>6</td>\n      <td>0.970000</td>\n      <td>0.780000</td>\n      <td>0.940000</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>decision_tree</td>\n      <td>74</td>\n      <td>62</td>\n      <td>62</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.013514</td>\n      <td>0.905396</td>\n      <td>0.323571</td>\n      <td>4</td>\n      <td>1.070016</td>\n      <td>18</td>\n      <td>9</td>\n      <td>0.864865</td>\n      <td>0.621622</td>\n      <td>0.864865</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>naive_bayes</td>\n      <td>74</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.013514</td>\n      <td>0.716652</td>\n      <td>0.040327</td>\n      <td>4</td>\n      <td>1.022882</td>\n      <td>9</td>\n      <td>5</td>\n      <td>0.986486</td>\n      <td>1.000000</td>\n      <td>0.932432</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>SVM_poly</td>\n      <td>148</td>\n      <td>18</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.013514</td>\n      <td>0.952703</td>\n      <td>0.335110</td>\n      <td>4</td>\n      <td>0.850961</td>\n      <td>24</td>\n      <td>7</td>\n      <td>0.918919</td>\n      <td>0.641892</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>decision_tree</td>\n      <td>662</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.419692</td>\n      <td>0.516237</td>\n      <td>0.458438</td>\n      <td>2</td>\n      <td>0.692252</td>\n      <td>211</td>\n      <td>16</td>\n      <td>0.643505</td>\n      <td>0.566465</td>\n      <td>0.549849</td>\n    </tr>\n  </tbody>\n</table>\n<p>432 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.DataFrame()\n",
    "dataset_fnames = os.listdir('/Users/esbessonngmail.com/Downloads/OpenML/data')\n",
    "for ind, fname in enumerate(dataset_fnames):\n",
    "    # print(f\"{ind + 1}/{len(dataset_fnames)}: {fname}\")\n",
    "    name = f'/Users/esbessonngmail.com/Downloads/OpenML/data/{fname}'\n",
    "    try:\n",
    "        raw_data = loadarff(name)\n",
    "        df_data = pd.DataFrame(raw_data[0])\n",
    "        str_df = df_data.select_dtypes([object])\n",
    "        str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "        for col in str_df:\n",
    "            df_data[col] = str_df[col]\n",
    "        features = get_all_features(df_data)\n",
    "        row = pd.DataFrame(features)\n",
    "        meta_df = pd.concat([meta_df, row], ignore_index=True, axis=0)\n",
    "        print(f\"Nominal file {fname}\")\n",
    "        print(features.values())\n",
    "    except Exception as e:\n",
    "        print(f\"Numeric file {fname}\")\n",
    "        print(e)\n",
    "meta_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'naive_bayes', 'SVM_poly', 'decision_tree'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/y1nxc5zd3c9_k18s4j2fstsw0000gn/T/ipykernel_9493/355765528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "X = meta_df.loc[:, ~meta_df.columns.isin(['best_algo', *available_classifiers.keys()])]\n",
    "X.fillna(0, inplace=True)\n",
    "y = meta_df['best_algo']\n",
    "print(set(y))\n",
    "colors = []\n",
    "color_map = {0 : 'red', 1: 'green', 2: 'blue'}\n",
    "for i in pd.factorize(y)[0]:\n",
    "    colors.append(color_map[i])\n",
    "for x in [X, norm_min_max(X.values)]:\n",
    "    pca = PCA(n_components=2)\n",
    "    x_new = pca.fit_transform(x)\n",
    "    plt.scatter(x_new[:, 0], x_new[:, 1], c=colors)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "203d4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular algo (naive): `decision_tree`\n",
      "Best algo on meta-dataset: `decision_tree`\n",
      "All predicted algos scores: `{'decision_tree': 0.7453703703703705, 'naive_bayes': 0.6550925925925926, 'SVM_poly': 0.6921296296296297}`\n",
      "Naive f-score: 0.5393518518518519\n"
     ]
    }
   ],
   "source": [
    "def naive_score(ys):\n",
    "    val_class = ys.mode()[0]\n",
    "    pred = [val_class] * len(ys)\n",
    "    print(f\"Most popular algo (naive): `{val_class}`\")\n",
    "    return f1_score(ys, pred, average='micro')\n",
    "\n",
    "xs = norm_min_max(X.values)\n",
    "ys = y.values\n",
    "all_scores = dict()\n",
    "for classifier_name in available_classifiers:\n",
    "    cls = available_classifiers[classifier_name]()\n",
    "    cls.fit(xs, ys)\n",
    "    pred = cls.predict(xs)\n",
    "    score = f1_score(ys, pred, average='micro')\n",
    "    all_scores[classifier_name] = score\n",
    "best = [k for k, v in all_scores.items() if v == max(all_scores.values())][0]\n",
    "best, scores = [best], all_scores\n",
    "naive = naive_score(y)\n",
    "print(f\"Best algo on meta-dataset: `{best[0]}`\")\n",
    "print(f\"All predicted algos scores: `{scores}`\")\n",
    "print(f'Naive f-score: {naive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}